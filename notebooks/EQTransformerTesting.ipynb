{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:01:36.430785900Z",
     "start_time": "2023-10-11T10:01:28.315137900Z"
    },
    "id": "jvhGVCgXVh56"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from queue import PriorityQueue\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import bottleneck as bn\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import obspy\n",
    "import torch\n",
    "import torch.multiprocessing as torchmp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from obspy.signal.trigger import trigger_onset\n",
    "from packaging import version\n",
    "\n",
    "import seisbench\n",
    "import seisbench.util as util\n",
    "from seisbench.util import in_notebook, log_lifecycle\n",
    "import seisbench.models as sbm\n",
    "\n",
    "from scipy import signal\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrrsVKy0UgY8"
   },
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:02:22.635069800Z",
     "start_time": "2023-10-11T10:02:22.616542400Z"
    },
    "cellView": "form",
    "id": "Dvu2bsBoUjb5"
   },
   "outputs": [],
   "source": [
    "class CustomLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM to be used with custom cells\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell, *cell_args, bidirectional=True, **cell_kwargs):\n",
    "        super(CustomLSTM, self).__init__()\n",
    "        self.cell_f = cell(*cell_args, **cell_kwargs)\n",
    "        self.bidirectional = bidirectional\n",
    "        if self.bidirectional:\n",
    "            self.cell_b = cell(*cell_args, **cell_kwargs)\n",
    "\n",
    "    def forward(self, input, state=None):\n",
    "        # Forward\n",
    "        state_f = state\n",
    "        outputs_f = []\n",
    "        for i in range(len(input)):\n",
    "            out, state_f = self.cell_f(input[i], state_f)\n",
    "            outputs_f += [out]\n",
    "\n",
    "        outputs_f = torch.stack(outputs_f)\n",
    "\n",
    "        if not self.bidirectional:\n",
    "            return outputs_f, None\n",
    "\n",
    "        # Backward\n",
    "        state_b = state\n",
    "        outputs_b = []\n",
    "        l = input.shape[0] - 1\n",
    "        for i in range(len(input)):\n",
    "            out, state_b = self.cell_b(input[l - i], state_b)\n",
    "            outputs_b += [out]\n",
    "\n",
    "        outputs_b = torch.flip(torch.stack(outputs_b), dims=[0])\n",
    "\n",
    "        output = torch.cat([outputs_f, outputs_b], dim=-1)\n",
    "\n",
    "        # Keep second argument for consistency with PyTorch LSTM\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:02:23.270317100Z",
     "start_time": "2023-10-11T10:02:23.247102Z"
    },
    "cellView": "form",
    "id": "A6z2MfsfUt4u"
   },
   "outputs": [],
   "source": [
    "def hard_sigmoid(x):\n",
    "    return torch.clip(0.2 * x + 0.5, 0, 1)\n",
    "\n",
    "class ActivationLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Cell using variable gating activation, by default hard sigmoid\n",
    "\n",
    "    If gate_activation=torch.sigmoid this is the standard LSTM cell\n",
    "\n",
    "    Uses recurrent dropout strategy from https://arxiv.org/abs/1603.05118 to match Keras implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, input_size, hidden_size, gate_activation=hard_sigmoid, recurrent_dropout=0\n",
    "    ):\n",
    "        super(ActivationLSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gate_activation = gate_activation\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "\n",
    "        self.weight_ih = nn.Parameter(torch.randn(4 * hidden_size, input_size))\n",
    "        self.weight_hh = nn.Parameter(torch.randn(4 * hidden_size, hidden_size))\n",
    "        self.bias_ih = nn.Parameter(torch.randn(4 * hidden_size))\n",
    "        self.bias_hh = nn.Parameter(torch.randn(4 * hidden_size))\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            for param in [self.weight_hh, self.weight_ih]:\n",
    "                for idx in range(4):\n",
    "                    mul = param.shape[0] // 4\n",
    "                    torch.nn.init.xavier_uniform_(param[idx * mul : (idx + 1) * mul])\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        if state is None:\n",
    "            hx = torch.zeros(\n",
    "                input.shape[0], self.hidden_size, device=input.device, dtype=input.dtype\n",
    "            )\n",
    "            cx = torch.zeros(\n",
    "                input.shape[0], self.hidden_size, device=input.device, dtype=input.dtype\n",
    "            )\n",
    "        else:\n",
    "            hx, cx = state\n",
    "        gates = (\n",
    "            torch.mm(input, self.weight_ih.t())\n",
    "            + self.bias_ih\n",
    "            + torch.mm(hx, self.weight_hh.t())\n",
    "            + self.bias_hh\n",
    "        )\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "\n",
    "        ingate = self.gate_activation(ingate)\n",
    "        forgetgate = self.gate_activation(forgetgate)\n",
    "        cellgate = torch.tanh(cellgate)\n",
    "        outgate = self.gate_activation(outgate)\n",
    "\n",
    "        if self.recurrent_dropout > 0:\n",
    "            cellgate = F.dropout(cellgate, p=self.recurrent_dropout)\n",
    "\n",
    "        cy = (forgetgate * cx) + (ingate * cellgate)\n",
    "        hy = outgate * torch.tanh(cy)\n",
    "\n",
    "        return hy, (hy, cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:02:51.119257200Z",
     "start_time": "2023-10-11T10:02:51.052936100Z"
    },
    "id": "WDQ6V7ZXTyiQ"
   },
   "outputs": [],
   "source": [
    "class EQTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    The EQTransformer from Mousavi et al. (2020)\n",
    "\n",
    "    Implementation adapted from the Github repository https://github.com/smousavi05/EQTransformer\n",
    "    Assumes padding=\"same\" and activation=\"relu\" as in the pretrained EQTransformer models\n",
    "\n",
    "    By instantiating the model with `from_pretrained(\"original\")` a binary compatible version of the original\n",
    "    EQTransformer with the original weights from Mousavi et al. (2020) can be loaded.\n",
    "\n",
    "    .. document_args:: seisbench.models EQTransformer\n",
    "\n",
    "    :param in_channels: Number of input channels, by default 3.\n",
    "    :param in_samples: Number of input samples per channel, by default 6000.\n",
    "                       The model expects input shape (in_channels, in_samples)\n",
    "    :param classes: Number of output classes, by default 2. The detection channel is not counted.\n",
    "    :param phases: Phase hints for the classes, by default \"PS\". Can be None.\n",
    "    :param res_cnn_blocks: Number of residual convolutional blocks\n",
    "    :param lstm_blocks: Number of LSTM blocks\n",
    "    :param drop_rate: Dropout rate\n",
    "    :param original_compatible: If True, uses a few custom layers for binary compatibility with original model\n",
    "                                from Mousavi et al. (2020).\n",
    "                                This option defaults to False.\n",
    "                                It is usually recommended to stick to the default value, as the custom layers show\n",
    "                                slightly worse performance than the PyTorch builtins.\n",
    "                                The exception is when loading the original weights using :py:func:`from_pretrained`.\n",
    "    :param norm: Data normalization strategy, either \"peak\" or \"std\".\n",
    "    :param kwargs: Keyword arguments passed to the constructor of :py:class:`WaveformModel`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=3,\n",
    "        in_samples=6000,\n",
    "        classes=2,\n",
    "        phases=\"PS\",\n",
    "        lstm_blocks=3,\n",
    "        drop_rate=0.1,\n",
    "        original_compatible=False,\n",
    "        sampling_rate=100,\n",
    "        norm=\"std\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_samples = in_samples\n",
    "        self.in_channels = in_channels\n",
    "        self.classes = classes\n",
    "        self.lstm_blocks = lstm_blocks\n",
    "        self.drop_rate = drop_rate\n",
    "        self.norm = norm\n",
    "\n",
    "        # Add options for conservative and the true original - see https://github.com/seisbench/seisbench/issues/96#issuecomment-1155158224\n",
    "        if original_compatible == True:\n",
    "            warnings.warn(\n",
    "                \"Using the non-conservative 'original' model, set `original_compatible='conservative' to use the more conservative model\"\n",
    "            )\n",
    "            original_compatible = \"non-conservative\"\n",
    "\n",
    "        if original_compatible:\n",
    "            eps = 1e-7  # See Issue #96 - original models use tensorflow default epsilon of 1e-7\n",
    "        else:\n",
    "            eps = 1e-5\n",
    "        self.original_compatible = original_compatible\n",
    "\n",
    "        if original_compatible and in_samples != 6000:\n",
    "            raise ValueError(\"original_compatible=True requires in_samples=6000.\")\n",
    "\n",
    "        self._phases = phases\n",
    "        if phases is not None and len(phases) != classes:\n",
    "            raise ValueError(\n",
    "                f\"Number of classes ({classes}) does not match number of phases ({len(phases)}).\"\n",
    "            )\n",
    "\n",
    "        # Parameters from EQTransformer repository\n",
    "        self.filters = [\n",
    "            8,\n",
    "            16,\n",
    "            16,\n",
    "            32,\n",
    "            32,\n",
    "            64,\n",
    "            64,\n",
    "        ]  # Number of filters for the convolutions\n",
    "        self.kernel_sizes = [11, 9, 7, 7, 5, 5, 3]  # Kernel sizes for the convolutions\n",
    "        self.res_cnn_kernels = [3, 3, 3, 3, 2, 3, 2]\n",
    "\n",
    "        # TODO: Add regularizers when training model\n",
    "        # kernel_regularizer=keras.regularizers.l2(1e-6),\n",
    "        # bias_regularizer=keras.regularizers.l1(1e-4),\n",
    "\n",
    "        # Encoder stack\n",
    "        self.encoder = Encoder(\n",
    "            input_channels=self.in_channels,\n",
    "            filters=self.filters,\n",
    "            kernel_sizes=self.kernel_sizes,\n",
    "            in_samples=self.in_samples,\n",
    "        )\n",
    "\n",
    "        # Res CNN Stack\n",
    "        self.res_cnn_stack = ResCNNStack(\n",
    "            kernel_sizes=self.res_cnn_kernels,\n",
    "            filters=self.filters[-1],\n",
    "            drop_rate=self.drop_rate,\n",
    "        )\n",
    "\n",
    "        # BiLSTM stack\n",
    "        self.bi_lstm_stack = BiLSTMStack(\n",
    "            blocks=self.lstm_blocks,\n",
    "            input_size=self.filters[-1],\n",
    "            drop_rate=self.drop_rate,\n",
    "            original_compatible=original_compatible,\n",
    "        )\n",
    "\n",
    "        # Global attention - two transformers\n",
    "        self.transformer_d0 = Transformer(\n",
    "            input_size=16, drop_rate=self.drop_rate, eps=eps\n",
    "        )\n",
    "        self.transformer_d = Transformer(\n",
    "            input_size=16, drop_rate=self.drop_rate, eps=eps\n",
    "        )\n",
    "\n",
    "        # Detection decoder and final Conv\n",
    "        self.decoder_d = Decoder(\n",
    "            input_channels=16,\n",
    "            filters=self.filters[::-1],\n",
    "            kernel_sizes=self.kernel_sizes[::-1],\n",
    "            out_samples=in_samples,\n",
    "            original_compatible=original_compatible,\n",
    "        )\n",
    "        self.conv_d = nn.Conv1d(\n",
    "            in_channels=self.filters[0], out_channels=1, kernel_size=11, padding=5\n",
    "        )\n",
    "\n",
    "        # Picking branches\n",
    "        self.pick_lstms = []\n",
    "        self.pick_attentions = []\n",
    "        self.pick_decoders = []\n",
    "        self.pick_convs = []\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "        for _ in range(self.classes):\n",
    "            if original_compatible == \"conservative\":\n",
    "                # The non-conservative model uses a sigmoid activiation as handled by the base nn.LSTM\n",
    "                lstm = CustomLSTM(ActivationLSTMCell, 16, 16, bidirectional=False)\n",
    "            else:\n",
    "                lstm = nn.LSTM(16, 16, bidirectional=False)\n",
    "            self.pick_lstms.append(lstm)\n",
    "\n",
    "            attention = SeqSelfAttention(input_size=16, attention_width=3, eps=eps)\n",
    "            self.pick_attentions.append(attention)\n",
    "\n",
    "            decoder = Decoder(\n",
    "                input_channels=16,\n",
    "                filters=self.filters[::-1],\n",
    "                kernel_sizes=self.kernel_sizes[::-1],\n",
    "                out_samples=in_samples,\n",
    "                original_compatible=original_compatible,\n",
    "            )\n",
    "            self.pick_decoders.append(decoder)\n",
    "\n",
    "            conv = nn.Conv1d(\n",
    "                in_channels=self.filters[0], out_channels=1, kernel_size=11, padding=5\n",
    "            )\n",
    "            self.pick_convs.append(conv)\n",
    "\n",
    "        self.pick_lstms = nn.ModuleList(self.pick_lstms)\n",
    "        self.pick_attentions = nn.ModuleList(self.pick_attentions)\n",
    "        self.pick_decoders = nn.ModuleList(self.pick_decoders)\n",
    "        self.pick_convs = nn.ModuleList(self.pick_convs)\n",
    "\n",
    "    def forward(self, x, logits=False):\n",
    "        assert x.ndim == 3\n",
    "        assert x.shape[1:] == (self.in_channels, self.in_samples)\n",
    "\n",
    "        # Shared encoder part\n",
    "        x = self.encoder(x)\n",
    "        x = self.res_cnn_stack(x)\n",
    "        x = self.bi_lstm_stack(x)\n",
    "        x, _ = self.transformer_d0(x)\n",
    "        x, _ = self.transformer_d(x)\n",
    "\n",
    "        # Detection part\n",
    "        detection = self.decoder_d(x)\n",
    "        if logits:\n",
    "            detection = self.conv_d(detection)\n",
    "        else:\n",
    "            detection = torch.sigmoid(self.conv_d(detection))\n",
    "        detection = torch.squeeze(detection, dim=1)  # Remove channel dimension\n",
    "\n",
    "        outputs = [detection]\n",
    "\n",
    "        # Pick parts\n",
    "        for lstm, attention, decoder, conv in zip(\n",
    "            self.pick_lstms, self.pick_attentions, self.pick_decoders, self.pick_convs\n",
    "        ):\n",
    "            px = x.permute(\n",
    "                2, 0, 1\n",
    "            )  # From batch, channels, sequence to sequence, batch, channels\n",
    "            px = lstm(px)[0]\n",
    "            px = self.dropout(px)\n",
    "            px = px.permute(\n",
    "                1, 2, 0\n",
    "            )  # From sequence, batch, channels to batch, channels, sequence\n",
    "            px, _ = attention(px)\n",
    "            px = decoder(px)\n",
    "            if logits:\n",
    "                pred = conv(px)\n",
    "            else:\n",
    "                pred = torch.sigmoid(conv(px))\n",
    "            pred = torch.squeeze(pred, dim=1)  # Remove channel dimension\n",
    "\n",
    "            outputs.append(pred)\n",
    "\n",
    "        return tuple(outputs)\n",
    "\n",
    "        # Cosine taper (very short, i.e., only six samples on each side)\n",
    "        tap = 0.5 * (1 + np.cos(np.linspace(np.pi, 2 * np.pi, 6)))\n",
    "        window[:, :6] *= tap\n",
    "        window[:, -6:] *= tap[::-1]\n",
    "\n",
    "        return window\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder stack\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, filters, kernel_sizes, in_samples):\n",
    "        super().__init__()\n",
    "\n",
    "        convs = []\n",
    "        pools = []\n",
    "        self.paddings = []\n",
    "        for in_channels, out_channels, kernel_size in zip(\n",
    "            [input_channels] + filters[:-1], filters, kernel_sizes\n",
    "        ):\n",
    "            convs.append(\n",
    "                nn.Conv1d(\n",
    "                    in_channels, out_channels, kernel_size, padding=kernel_size // 2\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # To be consistent with the behaviour in tensorflow,\n",
    "            # padding needs to be added for odd numbers of input_samples\n",
    "            padding = in_samples % 2\n",
    "\n",
    "            # Padding for MaxPool1d needs to be handled manually to conform with tf padding\n",
    "            self.paddings.append(padding)\n",
    "            pools.append(nn.MaxPool1d(2, padding=0))\n",
    "            in_samples = (in_samples + padding) // 2\n",
    "\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.pools = nn.ModuleList(pools)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv, pool, padding in zip(self.convs, self.pools, self.paddings):\n",
    "            x = torch.relu(conv(x))\n",
    "            if padding != 0:\n",
    "                # Only pad right, use -1e10 as negative infinity\n",
    "                x = F.pad(x, (0, padding), \"constant\", -1e10)\n",
    "            x = pool(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels,\n",
    "        filters,\n",
    "        kernel_sizes,\n",
    "        out_samples,\n",
    "        original_compatible=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.original_compatible = original_compatible\n",
    "\n",
    "        # We need to trim off the final sample sometimes to get to the right number of output samples\n",
    "        self.crops = []\n",
    "        current_samples = out_samples\n",
    "        for i, _ in enumerate(filters):\n",
    "            padding = current_samples % 2\n",
    "            current_samples = (current_samples + padding) // 2\n",
    "            if padding == 1:\n",
    "                self.crops.append(len(filters) - 1 - i)\n",
    "\n",
    "        convs = []\n",
    "        for in_channels, out_channels, kernel_size in zip(\n",
    "            [input_channels] + filters[:-1], filters, kernel_sizes\n",
    "        ):\n",
    "            convs.append(\n",
    "                nn.Conv1d(\n",
    "                    in_channels, out_channels, kernel_size, padding=kernel_size // 2\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = self.upsample(x)\n",
    "\n",
    "            if self.original_compatible:\n",
    "                if i == 3:\n",
    "                    x = x[:, :, 1:-1]\n",
    "            else:\n",
    "                if i in self.crops:\n",
    "                    x = x[:, :, :-1]\n",
    "\n",
    "            x = F.relu(conv(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResCNNStack(nn.Module):\n",
    "    def __init__(self, kernel_sizes, filters, drop_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        members = []\n",
    "        for ker in kernel_sizes:\n",
    "            members.append(ResCNNBlock(filters, ker, drop_rate))\n",
    "\n",
    "        self.members = nn.ModuleList(members)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for member in self.members:\n",
    "            x = member(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResCNNBlock(nn.Module):\n",
    "    def __init__(self, filters, ker, drop_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.manual_padding = False\n",
    "        if ker == 3:\n",
    "            padding = 1\n",
    "        else:\n",
    "            # ker == 2\n",
    "            # Manual padding emulate the padding in tensorflow\n",
    "            self.manual_padding = True\n",
    "            padding = 0\n",
    "\n",
    "        self.dropout = SpatialDropout1d(drop_rate)\n",
    "\n",
    "        self.norm1 = nn.BatchNorm1d(filters, eps=1e-3)\n",
    "        self.conv1 = nn.Conv1d(filters, filters, ker, padding=padding)\n",
    "\n",
    "        self.norm2 = nn.BatchNorm1d(filters, eps=1e-3)\n",
    "        self.conv2 = nn.Conv1d(filters, filters, ker, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.norm1(x)\n",
    "        y = F.relu(y)\n",
    "        y = self.dropout(y)\n",
    "        if self.manual_padding:\n",
    "            y = F.pad(y, (0, 1), \"constant\", 0)\n",
    "        y = self.conv1(y)\n",
    "\n",
    "        y = self.norm2(y)\n",
    "        y = F.relu(y)\n",
    "        y = self.dropout(y)\n",
    "        if self.manual_padding:\n",
    "            y = F.pad(y, (0, 1), \"constant\", 0)\n",
    "        y = self.conv2(y)\n",
    "\n",
    "        return x + y\n",
    "\n",
    "\n",
    "class BiLSTMStack(nn.Module):\n",
    "    def __init__(\n",
    "        self, blocks, input_size, drop_rate, hidden_size=16, original_compatible=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # First LSTM has a different input size as the subsequent ones\n",
    "        self.members = nn.ModuleList(\n",
    "            [\n",
    "                BiLSTMBlock(\n",
    "                    input_size,\n",
    "                    hidden_size,\n",
    "                    drop_rate,\n",
    "                    original_compatible=original_compatible,\n",
    "                )\n",
    "            ]\n",
    "            + [\n",
    "                BiLSTMBlock(\n",
    "                    hidden_size,\n",
    "                    hidden_size,\n",
    "                    drop_rate,\n",
    "                    original_compatible=original_compatible,\n",
    "                )\n",
    "                for _ in range(blocks - 1)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for member in self.members:\n",
    "            x = member(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BiLSTMBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, drop_rate, original_compatible=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if original_compatible == \"conservative\":\n",
    "            # The non-conservative model uses a sigmoid activiation as handled by the base nn.LSTM\n",
    "            self.lstm = CustomLSTM(ActivationLSTMCell, input_size, hidden_size)\n",
    "        elif original_compatible == \"non-conservative\":\n",
    "            self.lstm = CustomLSTM(\n",
    "                ActivationLSTMCell,\n",
    "                input_size,\n",
    "                hidden_size,\n",
    "                gate_activation=torch.sigmoid,\n",
    "            )\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "        self.conv = nn.Conv1d(2 * hidden_size, hidden_size, 1)\n",
    "        self.norm = nn.BatchNorm1d(hidden_size, eps=1e-3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(\n",
    "            2, 0, 1\n",
    "        )  # From batch, channels, sequence to sequence, batch, channels\n",
    "        x = self.lstm(x)[0]\n",
    "        x = self.dropout(x)\n",
    "        x = x.permute(\n",
    "            1, 2, 0\n",
    "        )  # From sequence, batch, channels to batch, channels, sequence\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_size, drop_rate, attention_width=None, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = SeqSelfAttention(\n",
    "            input_size, attention_width=attention_width, eps=eps\n",
    "        )\n",
    "        self.norm1 = LayerNormalization(input_size)\n",
    "        self.ff = FeedForward(input_size, drop_rate)\n",
    "        self.norm2 = LayerNormalization(input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y, weight = self.attention(x)\n",
    "        y = x + y\n",
    "        y = self.norm1(y)\n",
    "        y2 = self.ff(y)\n",
    "        y2 = y + y2\n",
    "        y2 = self.norm2(y2)\n",
    "\n",
    "        return y2, weight\n",
    "\n",
    "\n",
    "class SeqSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Additive self attention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, units=32, attention_width=None, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.attention_width = attention_width\n",
    "\n",
    "        self.Wx = nn.Parameter(uniform(-0.02, 0.02, input_size, units))\n",
    "        self.Wt = nn.Parameter(uniform(-0.02, 0.02, input_size, units))\n",
    "        self.bh = nn.Parameter(torch.zeros(units))\n",
    "\n",
    "        self.Wa = nn.Parameter(uniform(-0.02, 0.02, units, 1))\n",
    "        self.ba = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch, channels, time)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # to (batch, time, channels)\n",
    "\n",
    "        q = torch.unsqueeze(\n",
    "            torch.matmul(x, self.Wt), 2\n",
    "        )  # Shape (batch, time, 1, channels)\n",
    "        k = torch.unsqueeze(\n",
    "            torch.matmul(x, self.Wx), 1\n",
    "        )  # Shape (batch, 1, time, channels)\n",
    "\n",
    "        h = torch.tanh(q + k + self.bh)\n",
    "\n",
    "        # Emissions\n",
    "        e = torch.squeeze(\n",
    "            torch.matmul(h, self.Wa) + self.ba, -1\n",
    "        )  # Shape (batch, time, time)\n",
    "\n",
    "        # This is essentially softmax with an additional attention component.\n",
    "        e = (\n",
    "            e - torch.max(e, dim=-1, keepdim=True).values\n",
    "        )  # In versions <= 0.2.1 e was incorrectly normalized by max(x)\n",
    "        e = torch.exp(e)\n",
    "        if self.attention_width is not None:\n",
    "            lower = (\n",
    "                torch.arange(0, e.shape[1], device=e.device) - self.attention_width // 2\n",
    "            )\n",
    "            upper = lower + self.attention_width\n",
    "            indices = torch.unsqueeze(torch.arange(0, e.shape[1], device=e.device), 1)\n",
    "            mask = torch.logical_and(lower <= indices, indices < upper)\n",
    "            e = torch.where(mask, e, torch.zeros_like(e))\n",
    "\n",
    "        a = e / (torch.sum(e, dim=-1, keepdim=True) + self.eps)\n",
    "\n",
    "        v = torch.matmul(a, x)\n",
    "\n",
    "        v = v.permute(0, 2, 1)  # to (batch, channels, time)\n",
    "\n",
    "        return v, a\n",
    "\n",
    "\n",
    "def uniform(a, b, *args):\n",
    "    return a + (b - a) * torch.rand(*args)\n",
    "\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, filters, eps=1e-14):\n",
    "        super().__init__()\n",
    "\n",
    "        gamma = torch.ones(filters, 1)\n",
    "        self.gamma = nn.Parameter(gamma)\n",
    "        beta = torch.zeros(filters, 1)\n",
    "        self.beta = nn.Parameter(beta)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = torch.mean(x, 1, keepdim=True)\n",
    "        var = torch.mean((x - mean) ** 2, 1, keepdim=True) + self.eps\n",
    "        std = torch.sqrt(var)\n",
    "        outputs = (x - mean) / std\n",
    "\n",
    "        outputs = outputs * self.gamma\n",
    "        outputs = outputs + self.beta\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, io_size, drop_rate, hidden_size=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin1 = nn.Linear(io_size, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, io_size)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # To (batch, time, channel)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = x.permute(0, 2, 1)  # To (batch, channel, time)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpatialDropout1d(nn.Module):\n",
    "    def __init__(self, drop_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.drop_rate = drop_rate\n",
    "        self.dropout = nn.Dropout2d(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(dim=-1)  # Add fake dimension\n",
    "        x = self.dropout(x)\n",
    "        x = x.squeeze(dim=-1)  # Remove fake dimension\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:03:23.908860300Z",
     "start_time": "2023-10-11T10:03:23.854204800Z"
    },
    "id": "PGuu0bwZWULj"
   },
   "outputs": [],
   "source": [
    "model = EQTransformer(in_channels=1, in_samples=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:03:48.863586300Z",
     "start_time": "2023-10-11T10:03:48.816573300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3iOjiUZYnee",
    "outputId": "b960c067-c6b9-4fd8-97d0-f7764b3de978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape input: (1000, 300, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# pulse_width_range = [10,30]\n",
    "pulse_height_range = [3,10]\n",
    "pulse_start_range = [50,250]\n",
    "gauss_width = 11\n",
    "onset_shift = 0 # int(gauss_width/2)\n",
    "\n",
    "input,target = [],[]\n",
    "\n",
    "for i in range(1000):\n",
    "  # e = signal.gaussian(random.randint(pulse_width_range[0],pulse_width_range[1]), std=1)\n",
    "  e = signal.windows.gaussian(gauss_width, std=2)\n",
    "\n",
    "  noise = np.random.normal(0, 1, 300)\n",
    "\n",
    "  start = random.randint(pulse_start_range[0],pulse_start_range[1])\n",
    "  noisy_pulse = np.copy(noise)\n",
    "  noisy_pulse[start+onset_shift:start+e.shape[0]+onset_shift] += random.randint(pulse_height_range[0],pulse_height_range[1])*e\n",
    "  # noisy_pulse *= [-1,1][random.randrange(2)]\n",
    "  label= np.zeros_like(noisy_pulse)\n",
    "  label[start:start+e.shape[0]] += e\n",
    "\n",
    "  input.append(noisy_pulse)\n",
    "  target.append(label)\n",
    "\n",
    "input = np.expand_dims(input, axis=-1)\n",
    "input = np.expand_dims(input, axis=-1)\n",
    "\n",
    "target = np.expand_dims(target, axis=-1)\n",
    "target = np.expand_dims(target, axis=-1)\n",
    "target = np.concatenate((target,1 - target),axis=3)\n",
    "\n",
    "print('Shape input:',np.shape(input))\n",
    "\n",
    "input_test,target_test = [],[]\n",
    "\n",
    "for i in range(128):\n",
    "  e = signal.windows.gaussian(gauss_width, std=2)\n",
    "\n",
    "  noise = np.random.normal(0, 1, 300)\n",
    "\n",
    "  start = random.randint(pulse_start_range[0],pulse_start_range[1])\n",
    "  noisy_pulse = np.copy(noise)\n",
    "  noisy_pulse[start+onset_shift:start+e.shape[0]+onset_shift] += random.randint(pulse_height_range[0],pulse_height_range[1])*e\n",
    "  # noisy_pulse *= [-1,1][random.randrange(2)]\n",
    "\n",
    "  label= np.zeros_like(noisy_pulse)\n",
    "  label[start:start+e.shape[0]] += e\n",
    "\n",
    "  input_test.append(noisy_pulse)\n",
    "  target_test.append(label)\n",
    "\n",
    "input_test = np.expand_dims(input_test, axis=-1)\n",
    "input_test = np.expand_dims(input_test, axis=-1)\n",
    "\n",
    "target_test = np.expand_dims(target_test, axis=-1)\n",
    "target_test = np.expand_dims(target_test, axis=-1)\n",
    "target_test = np.concatenate((target_test,1 - target_test),axis=3)\n",
    "\n",
    "#print(input.shape, target.shape, input_test.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:03:53.363537400Z",
     "start_time": "2023-10-11T10:03:53.338035Z"
    },
    "id": "d4qkBDZTY814"
   },
   "outputs": [],
   "source": [
    "# Main execution\n",
    "input_tensor = torch.tensor(input.transpose(0, 3, 1, 2), dtype=torch.float32).squeeze(3)\n",
    "target_tensor = torch.tensor(target.transpose(0, 3, 1, 2), dtype=torch.float32).squeeze(3)\n",
    "input_test_tensor = torch.tensor(input_test.transpose(0, 3, 1, 2), dtype=torch.float32).squeeze(3)\n",
    "target_test_tensor = torch.tensor(target_test.transpose(0, 3, 1, 2), dtype=torch.float32).squeeze(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:04:04.139587900Z",
     "start_time": "2023-10-11T10:04:03.029379100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iv_hi0RuZVym",
    "outputId": "612054e9-9fd2-4173-ffdb-9fd6d31baf93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5044, 0.5049, 0.5054,  ..., 0.5091, 0.5081, 0.5089],\n",
       "         [0.5044, 0.5049, 0.5055,  ..., 0.5092, 0.5082, 0.5090],\n",
       "         [0.5045, 0.5049, 0.5055,  ..., 0.5092, 0.5082, 0.5089],\n",
       "         ...,\n",
       "         [0.5044, 0.5049, 0.5055,  ..., 0.5092, 0.5083, 0.5090],\n",
       "         [0.5045, 0.5049, 0.5054,  ..., 0.5091, 0.5082, 0.5089],\n",
       "         [0.5044, 0.5049, 0.5054,  ..., 0.5093, 0.5083, 0.5090]],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " tensor([[0.4856, 0.4861, 0.4866,  ..., 0.4842, 0.4826, 0.4831],\n",
       "         [0.4856, 0.4861, 0.4865,  ..., 0.4842, 0.4826, 0.4831],\n",
       "         [0.4856, 0.4861, 0.4866,  ..., 0.4842, 0.4826, 0.4831],\n",
       "         ...,\n",
       "         [0.4856, 0.4861, 0.4866,  ..., 0.4842, 0.4826, 0.4831],\n",
       "         [0.4856, 0.4861, 0.4865,  ..., 0.4842, 0.4826, 0.4831],\n",
       "         [0.4856, 0.4861, 0.4866,  ..., 0.4842, 0.4826, 0.4831]],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " tensor([[0.5068, 0.5060, 0.5053,  ..., 0.5043, 0.5041, 0.5042],\n",
       "         [0.5068, 0.5060, 0.5053,  ..., 0.5042, 0.5041, 0.5042],\n",
       "         [0.5067, 0.5060, 0.5053,  ..., 0.5043, 0.5041, 0.5042],\n",
       "         ...,\n",
       "         [0.5068, 0.5060, 0.5053,  ..., 0.5043, 0.5041, 0.5042],\n",
       "         [0.5068, 0.5060, 0.5053,  ..., 0.5043, 0.5041, 0.5043],\n",
       "         [0.5068, 0.5060, 0.5053,  ..., 0.5043, 0.5041, 0.5042]],\n",
       "        grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T11:06:02.806778900Z",
     "start_time": "2023-10-11T11:06:00.197908400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for key '/SNR' assigned to variable 'SNR'\n",
      "DataFrame for key '/X' assigned to variable 'X'\n",
      "DataFrame for key '/Y' assigned to variable 'Y'\n",
      "DataFrame for key '/dist' assigned to variable 'dist'\n",
      "DataFrame for key '/eve_id' assigned to variable 'eve_id'\n",
      "DataFrame for key '/mags' assigned to variable 'mags'\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "def recursively_extract_datasets(h5_object, current_path='', data_dict={}):\n",
    "    \"\"\"Recursively navigate through groups and extract datasets.\"\"\"\n",
    "    if isinstance(h5_object, h5py.Group):\n",
    "        # If this is a group, navigate its children\n",
    "        for key in h5_object.keys():\n",
    "            new_path = current_path + '/' + key\n",
    "            recursively_extract_datasets(h5_object[key], new_path, data_dict)\n",
    "    elif isinstance(h5_object, h5py.Dataset):\n",
    "        # If this is a dataset, save it in the dictionary\n",
    "        data = h5_object[()]\n",
    "        data_dict[current_path] = pd.DataFrame(data)\n",
    "    return data_dict\n",
    "\n",
    "def hdf5_key_to_variable_name(key):\n",
    "    \"\"\"Convert an HDF5 key to a valid Python variable name.\"\"\"\n",
    "    return key.replace(\"/\", \"_\").strip(\"_\")\n",
    "\n",
    "# Path to your HDF5 file\n",
    "file_path = \"../data/HS4_training_data_v01.h5\"\n",
    "\n",
    "dataframes = {}\n",
    "# Open the file and extract its datasets\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    dataframes = recursively_extract_datasets(f)\n",
    "\n",
    "# Assign each DataFrame to a dynamically created variable\n",
    "for key, df in dataframes.items():\n",
    "    var_name = hdf5_key_to_variable_name(key)\n",
    "    globals()[var_name] = df\n",
    "    print(f\"DataFrame for key '{key}' assigned to variable '{var_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEAD Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqt_model = sbm.EQTransformer.from_pretrained(\"stead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_model = sbm.PhaseNet.from_pretrained(\"stead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhaseNet(\n",
       "  (inc): Conv1d(3, 8, kernel_size=(7,), stride=(1,), padding=same)\n",
       "  (in_bn): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (down_branch): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Conv1d(8, 8, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(8, 8, kernel_size=(7,), stride=(4,), padding=(3,), bias=False)\n",
       "      (3): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Conv1d(8, 16, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(16, 16, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): Conv1d(16, 32, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(32, 32, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): Conv1d(32, 64, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(64, 64, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): ModuleList(\n",
       "      (0): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2-3): 2 x None\n",
       "    )\n",
       "  )\n",
       "  (up_branch): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): ConvTranspose1d(128, 64, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(128, 64, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): ConvTranspose1d(64, 32, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(64, 32, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): ConvTranspose1d(32, 16, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(32, 16, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): ConvTranspose1d(16, 8, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(16, 8, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (out): Conv1d(8, 3, kernel_size=(1,), stride=(1,), padding=same)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_eq = '..//data//chunk3.csv'\n",
    "file_name_eq = '..//data//chunk3.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_noise = '..//data//chunk1.csv'\n",
    "file_name_noise = '..//data//chunk1.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jp/cc_r_y3x6clgl7b4rwk3lgfw0000gn/T/ipykernel_23095/2032212684.py:2: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    }
   ],
   "source": [
    "# reading the csv file into a dataframe:\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_waves = 1000\n",
    "# randomise indexes\n",
    "idxs = pd.Series(range(1, len(df))).sample(n=num_waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files2waveTensor(csv_file, file_name, num_waves):\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    idxs = pd.Series(range(1, len(df))).sample(n=num_waves)\n",
    "    # making a list of trace names for the selected data\n",
    "    ev_list = df['trace_name'][idxs].to_list()\n",
    "\n",
    "    # retrieving selected waveforms from the hdf5 file: \n",
    "    dtfl = h5py.File(file_name, 'r')\n",
    "\n",
    "    wave_tensor = torch.empty(num_waves, 3, 6000)\n",
    "    labels = torch.empty(num_waves, 3)\n",
    "\n",
    "    for i, evi in enumerate(ev_list):\n",
    "        dataset = dtfl.get('data/'+str(evi)) \n",
    "        data = np.array(dataset)\n",
    "        wave_tensor[i] = torch.transpose(torch.Tensor(data), 0, 1)\n",
    "        \n",
    "        labels[i] = torch.Tensor((dataset.attrs['p_arrival_sample'], \n",
    "                                dataset.attrs['s_arrival_sample'], \n",
    "                                dataset.attrs['coda_end_sample'][0][0]))\n",
    "    \n",
    "    return wave_tensor, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, num_waves, eq = False):\n",
    "    preds = torch.empty(num_waves, 3, 6000)\n",
    "    pick_preds = torch.empty(num_waves, 3)\n",
    "    \n",
    "    for i in range(num_waves):\n",
    "        if (eq): preds[i] = torch.concat(model(wave_tensor[i].unsqueeze(0)))\n",
    "        else: preds[i] = model(wave_tensor[i].unsqueeze(0))\n",
    "        pick_preds[i, 0] = preds[i][0].argmax()\n",
    "        pick_preds[i, 1] = preds[i][1].argmax()\n",
    "        \n",
    "    return preds, pick_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_pn, pick_preds_pn = get_preds(pn_model, num_waves)\n",
    "preds_eq, pick_preds_eq = get_preds(eqt_model, num_waves, eq=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ROC curve plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_pn_maxs = (preds_pn[:, 0].max(axis = 1)[0], preds_pn[:, 1].max(axis = 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_rates(eq_vec, noise_vec, num_thetas = 100):\n",
    "    true_positives = np.empty(num_thetas)\n",
    "    false_positives = np.empty(num_thetas)\n",
    "    \n",
    "    for i, theta in enumerate(np.linspace(0,1,num_thetas)):\n",
    "        true_positives[i] = (eq_vec > theta).sum()\n",
    "        \n",
    "    for i, theta in enumerate(np.linspace(0,1,num_thetas)):\n",
    "        false_positives[i] = (noise_vec > theta).sum()\n",
    "    \n",
    "    # TPR, FPR\n",
    "    return true_positives / len(eq_vec), false_positives / len(noise_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_p, fpr_p = roc_rates(preds_pn_maxs[0], )\n",
    "tpr_s, fpr_s = roc_rates(preds_pn_maxs[1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred0:  965 , Label0:  973\n",
      "Pred1:  1856 , Label1:  1887\n",
      "Pred0:  784 , Label0:  900\n",
      "Pred1:  1324 , Label1:  1325\n",
      "Pred0:  499 , Label0:  500\n",
      "Pred1:  986 , Label1:  1005\n",
      "Pred0:  488 , Label0:  500\n",
      "Pred1:  782 , Label1:  790\n",
      "Pred0:  498 , Label0:  500\n",
      "Pred1:  1470 , Label1:  1472\n",
      "Pred0:  886 , Label0:  898\n",
      "Pred1:  1214 , Label1:  1223\n",
      "Pred0:  696 , Label0:  700\n",
      "Pred1:  950 , Label1:  958\n",
      "Pred0:  602 , Label0:  600\n",
      "Pred1:  895 , Label1:  887\n",
      "Pred0:  502 , Label0:  508\n",
      "Pred1:  1799 , Label1:  1799\n",
      "Pred0:  443 , Label0:  600\n",
      "Pred1:  597 , Label1:  737\n",
      "Pred0:  897 , Label0:  900\n",
      "Pred1:  2259 , Label1:  2321\n",
      "Pred0:  781 , Label0:  800\n",
      "Pred1:  1105 , Label1:  1114\n",
      "Pred0:  678 , Label0:  700\n",
      "Pred1:  1030 , Label1:  1030\n",
      "Pred0:  496 , Label0:  500\n",
      "Pred1:  711 , Label1:  716\n",
      "Pred0:  973 , Label0:  900\n",
      "Pred1:  2919 , Label1:  2922\n",
      "Pred0:  586 , Label0:  600\n",
      "Pred1:  755 , Label1:  766\n",
      "Pred0:  864 , Label0:  900\n",
      "Pred1:  1931 , Label1:  1903\n",
      "Pred0:  865 , Label0:  900\n",
      "Pred1:  1154 , Label1:  1151\n",
      "Pred0:  437 , Label0:  400\n",
      "Pred1:  1377 , Label1:  1369\n",
      "Pred0:  378 , Label0:  400\n",
      "Pred1:  411 , Label1:  596\n",
      "Pred0:  802 , Label0:  800\n",
      "Pred1:  1022 , Label1:  1024\n",
      "Pred0:  675 , Label0:  700\n",
      "Pred1:  1747 , Label1:  1741\n",
      "Pred0:  658 , Label0:  600\n",
      "Pred1:  2171 , Label1:  2188\n",
      "Pred0:  759 , Label0:  800\n",
      "Pred1:  1184 , Label1:  1187\n",
      "Pred0:  395 , Label0:  400\n",
      "Pred1:  1259 , Label1:  1246\n",
      "Pred0:  472 , Label0:  499\n",
      "Pred1:  1679 , Label1:  1672\n",
      "Pred0:  738 , Label0:  600\n",
      "Pred1:  2479 , Label1:  2485\n",
      "Pred0:  694 , Label0:  700\n",
      "Pred1:  1176 , Label1:  1175\n",
      "Pred0:  888 , Label0:  900\n",
      "Pred1:  1574 , Label1:  1508\n",
      "Pred0:  502 , Label0:  500\n",
      "Pred1:  1079 , Label1:  1029\n",
      "Pred0:  699 , Label0:  700\n",
      "Pred1:  1284 , Label1:  1286\n",
      "Pred0:  512 , Label0:  500\n",
      "Pred1:  770 , Label1:  781\n",
      "Pred0:  745 , Label0:  700\n",
      "Pred1:  1587 , Label1:  3168\n",
      "Pred0:  668 , Label0:  700\n",
      "Pred1:  1115 , Label1:  1216\n",
      "Pred0:  788 , Label0:  800\n",
      "Pred1:  1246 , Label1:  1257\n",
      "Pred0:  658 , Label0:  700\n",
      "Pred1:  1252 , Label1:  1252\n",
      "Pred0:  853 , Label0:  800\n",
      "Pred1:  1675 , Label1:  1629\n",
      "Pred0:  444 , Label0:  500\n",
      "Pred1:  754 , Label1:  767\n",
      "Pred0:  492 , Label0:  500\n",
      "Pred1:  830 , Label1:  824\n",
      "Pred0:  766 , Label0:  800\n",
      "Pred1:  2251 , Label1:  2262\n",
      "Pred0:  474 , Label0:  500\n",
      "Pred1:  1684 , Label1:  1702\n",
      "Pred0:  559 , Label0:  600\n",
      "Pred1:  1623 , Label1:  1590\n",
      "Pred0:  887 , Label0:  900\n",
      "Pred1:  1887 , Label1:  1888\n",
      "Pred0:  391 , Label0:  399\n",
      "Pred1:  1235 , Label1:  1240\n",
      "Pred0:  806 , Label0:  800\n",
      "Pred1:  1114 , Label1:  1124\n",
      "Pred0:  888 , Label0:  891\n",
      "Pred1:  1850 , Label1:  1850\n",
      "Pred0:  804 , Label0:  800\n",
      "Pred1:  1366 , Label1:  1377\n",
      "Pred0:  386 , Label0:  400\n",
      "Pred1:  644 , Label1:  656\n",
      "Pred0:  900 , Label0:  901\n",
      "Pred1:  1408 , Label1:  1410\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  1130 , Label1:  1136\n",
      "Pred0:  805 , Label0:  800\n",
      "Pred1:  991 , Label1:  1016\n",
      "Pred0:  882 , Label0:  900\n",
      "Pred1:  1263 , Label1:  1260\n",
      "Pred0:  392 , Label0:  400\n",
      "Pred1:  588 , Label1:  598\n",
      "Pred0:  578 , Label0:  600\n",
      "Pred1:  1303 , Label1:  1323\n",
      "Pred0:  868 , Label0:  899\n",
      "Pred1:  1307 , Label1:  1296\n",
      "Pred0:  883 , Label0:  900\n",
      "Pred1:  1231 , Label1:  1223\n",
      "Pred0:  882 , Label0:  900\n",
      "Pred1:  1616 , Label1:  1616\n",
      "Pred0:  651 , Label0:  500\n",
      "Pred1:  851 , Label1:  865\n",
      "Pred0:  490 , Label0:  499\n",
      "Pred1:  692 , Label1:  708\n",
      "Pred0:  711 , Label0:  700\n",
      "Pred1:  1136 , Label1:  1137\n",
      "Pred0:  890 , Label0:  900\n",
      "Pred1:  1330 , Label1:  1302\n",
      "Pred0:  758 , Label0:  800\n",
      "Pred1:  1293 , Label1:  1297\n",
      "Pred0:  766 , Label0:  800\n",
      "Pred1:  1359 , Label1:  1355\n",
      "Pred0:  382 , Label0:  400\n",
      "Pred1:  763 , Label1:  780\n",
      "Pred0:  600 , Label0:  600\n",
      "Pred1:  1759 , Label1:  1734\n",
      "Pred0:  767 , Label0:  800\n",
      "Pred1:  1891 , Label1:  1882\n",
      "Pred0:  600 , Label0:  600\n",
      "Pred1:  1010 , Label1:  1027\n",
      "Pred0:  881 , Label0:  900\n",
      "Pred1:  1608 , Label1:  1609\n",
      "Pred0:  498 , Label0:  500\n",
      "Pred1:  795 , Label1:  786\n",
      "Pred0:  578 , Label0:  600\n",
      "Pred1:  1078 , Label1:  1073\n",
      "Pred0:  790 , Label0:  800\n",
      "Pred1:  1045 , Label1:  1053\n",
      "Pred0:  502 , Label0:  500\n",
      "Pred1:  782 , Label1:  773\n",
      "Pred0:  402 , Label0:  400\n",
      "Pred1:  1284 , Label1:  1274\n",
      "Pred0:  406 , Label0:  400\n",
      "Pred1:  1094 , Label1:  1074\n",
      "Pred0:  463 , Label0:  500\n",
      "Pred1:  1921 , Label1:  1917\n",
      "Pred0:  584 , Label0:  500\n",
      "Pred1:  1459 , Label1:  1563\n",
      "Pred0:  742 , Label0:  800\n",
      "Pred1:  1109 , Label1:  1107\n",
      "Pred0:  666 , Label0:  700\n",
      "Pred1:  1186 , Label1:  1166\n",
      "Pred0:  673 , Label0:  700\n",
      "Pred1:  1137 , Label1:  1142\n",
      "Pred0:  568 , Label0:  600\n",
      "Pred1:  866 , Label1:  858\n",
      "Pred0:  459 , Label0:  503\n",
      "Pred1:  719 , Label1:  721\n",
      "Pred0:  590 , Label0:  600\n",
      "Pred1:  1667 , Label1:  1705\n",
      "Pred0:  756 , Label0:  800\n",
      "Pred1:  1556 , Label1:  1506\n",
      "Pred0:  801 , Label0:  800\n",
      "Pred1:  2130 , Label1:  2126\n",
      "Pred0:  792 , Label0:  790\n",
      "Pred1:  1987 , Label1:  1983\n",
      "Pred0:  482 , Label0:  500\n",
      "Pred1:  1563 , Label1:  1563\n",
      "Pred0:  801 , Label0:  800\n",
      "Pred1:  3723 , Label1:  3733\n",
      "Pred0:  482 , Label0:  500\n",
      "Pred1:  709 , Label1:  714\n",
      "Pred0:  419 , Label0:  400\n",
      "Pred1:  1531 , Label1:  1549\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  516 , Label1:  529\n",
      "Pred0:  488 , Label0:  497\n",
      "Pred1:  1179 , Label1:  1184\n",
      "Pred0:  563 , Label0:  600\n",
      "Pred1:  1391 , Label1:  1387\n",
      "Pred0:  891 , Label0:  900\n",
      "Pred1:  1078 , Label1:  1081\n",
      "Pred0:  850 , Label0:  900\n",
      "Pred1:  1246 , Label1:  1246\n",
      "Pred0:  943 , Label0:  700\n",
      "Pred1:  3498 , Label1:  3512\n",
      "Pred0:  776 , Label0:  800\n",
      "Pred1:  1317 , Label1:  1316\n",
      "Pred0:  708 , Label0:  700\n",
      "Pred1:  1032 , Label1:  1022\n",
      "Pred0:  564 , Label0:  700\n",
      "Pred1:  971 , Label1:  957\n",
      "Pred0:  902 , Label0:  903\n",
      "Pred1:  1915 , Label1:  1916\n",
      "Pred0:  728 , Label0:  699\n",
      "Pred1:  1638 , Label1:  1647\n",
      "Pred0:  870 , Label0:  900\n",
      "Pred1:  1295 , Label1:  1304\n",
      "Pred0:  376 , Label0:  402\n",
      "Pred1:  706 , Label1:  708\n",
      "Pred0:  488 , Label0:  500\n",
      "Pred1:  730 , Label1:  744\n",
      "Pred0:  912 , Label0:  900\n",
      "Pred1:  2043 , Label1:  2078\n",
      "Pred0:  698 , Label0:  700\n",
      "Pred1:  980 , Label1:  980\n",
      "Pred0:  417 , Label0:  400\n",
      "Pred1:  783 , Label1:  781\n",
      "Pred0:  578 , Label0:  600\n",
      "Pred1:  1144 , Label1:  1158\n",
      "Pred0:  596 , Label0:  600\n",
      "Pred1:  952 , Label1:  924\n",
      "Pred0:  447 , Label0:  500\n",
      "Pred1:  1039 , Label1:  1047\n",
      "Pred0:  898 , Label0:  900\n",
      "Pred1:  1286 , Label1:  1283\n",
      "Pred0:  470 , Label0:  400\n",
      "Pred1:  1427 , Label1:  1419\n",
      "Pred0:  570 , Label0:  700\n",
      "Pred1:  2207 , Label1:  2242\n",
      "Pred0:  788 , Label0:  500\n",
      "Pred1:  1423 , Label1:  1412\n",
      "Pred0:  792 , Label0:  800\n",
      "Pred1:  1142 , Label1:  1156\n",
      "Pred0:  498 , Label0:  497\n",
      "Pred1:  908 , Label1:  911\n",
      "Pred0:  677 , Label0:  697\n",
      "Pred1:  805 , Label1:  813\n",
      "Pred0:  458 , Label0:  451\n",
      "Pred1:  690 , Label1:  696\n",
      "Pred0:  806 , Label0:  812\n",
      "Pred1:  2035 , Label1:  2007\n",
      "Pred0:  570 , Label0:  600\n",
      "Pred1:  1411 , Label1:  1432\n",
      "Pred0:  784 , Label0:  800\n",
      "Pred1:  1248 , Label1:  1247\n",
      "Pred0:  691 , Label0:  700\n",
      "Pred1:  1335 , Label1:  1293\n",
      "Pred0:  935 , Label0:  900\n",
      "Pred1:  2235 , Label1:  2242\n",
      "Pred0:  402 , Label0:  404\n",
      "Pred1:  732 , Label1:  737\n",
      "Pred0:  1750 , Label0:  900\n",
      "Pred1:  1825 , Label1:  1825\n",
      "Pred0:  386 , Label0:  400\n",
      "Pred1:  798 , Label1:  807\n",
      "Pred0:  684 , Label0:  700\n",
      "Pred1:  1734 , Label1:  1730\n",
      "Pred0:  698 , Label0:  698\n",
      "Pred1:  731 , Label1:  816\n",
      "Pred0:  792 , Label0:  800\n",
      "Pred1:  1046 , Label1:  1055\n",
      "Pred0:  805 , Label0:  800\n",
      "Pred1:  1190 , Label1:  1134\n",
      "Pred0:  464 , Label0:  500\n",
      "Pred1:  734 , Label1:  746\n",
      "Pred0:  802 , Label0:  800\n",
      "Pred1:  1279 , Label1:  1291\n",
      "Pred0:  498 , Label0:  500\n",
      "Pred1:  868 , Label1:  870\n",
      "Pred0:  7 , Label0:  400\n",
      "Pred1:  1093 , Label1:  1096\n",
      "Pred0:  588 , Label0:  600\n",
      "Pred1:  730 , Label1:  742\n",
      "Pred0:  478 , Label0:  500\n",
      "Pred1:  783 , Label1:  806\n",
      "Pred0:  510 , Label0:  500\n",
      "Pred1:  1967 , Label1:  1948\n",
      "Pred0:  580 , Label0:  600\n",
      "Pred1:  1571 , Label1:  1566\n",
      "Pred0:  583 , Label0:  600\n",
      "Pred1:  1487 , Label1:  1467\n",
      "Pred0:  678 , Label0:  696\n",
      "Pred1:  1014 , Label1:  1013\n",
      "Pred0:  1437 , Label0:  600\n",
      "Pred1:  1951 , Label1:  1954\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  1328 , Label1:  1321\n",
      "Pred0:  887 , Label0:  900\n",
      "Pred1:  3287 , Label1:  3280\n",
      "Pred0:  590 , Label0:  600\n",
      "Pred1:  870 , Label1:  888\n",
      "Pred0:  696 , Label0:  700\n",
      "Pred1:  916 , Label1:  941\n",
      "Pred0:  800 , Label0:  801\n",
      "Pred1:  1034 , Label1:  1047\n",
      "Pred0:  867 , Label0:  700\n",
      "Pred1:  947 , Label1:  4212\n",
      "Pred0:  908 , Label0:  900\n",
      "Pred1:  1412 , Label1:  1402\n",
      "Pred0:  1068 , Label0:  600\n",
      "Pred1:  1697 , Label1:  1694\n",
      "Pred0:  670 , Label0:  700\n",
      "Pred1:  1091 , Label1:  1076\n",
      "Pred0:  401 , Label0:  400\n",
      "Pred1:  632 , Label1:  633\n",
      "Pred0:  491 , Label0:  500\n",
      "Pred1:  1943 , Label1:  1952\n",
      "Pred0:  514 , Label0:  500\n",
      "Pred1:  862 , Label1:  868\n",
      "Pred0:  886 , Label0:  900\n",
      "Pred1:  1054 , Label1:  1062\n",
      "Pred0:  786 , Label0:  800\n",
      "Pred1:  803 , Label1:  1001\n",
      "Pred0:  504 , Label0:  500\n",
      "Pred1:  994 , Label1:  1008\n",
      "Pred0:  1258 , Label0:  900\n",
      "Pred1:  2823 , Label1:  2760\n",
      "Pred0:  1632 , Label0:  1000\n",
      "Pred1:  2203 , Label1:  1605\n",
      "Pred0:  602 , Label0:  599\n",
      "Pred1:  982 , Label1:  984\n",
      "Pred0:  805 , Label0:  800\n",
      "Pred1:  1343 , Label1:  1344\n",
      "Pred0:  865 , Label0:  800\n",
      "Pred1:  1247 , Label1:  1250\n",
      "Pred0:  591 , Label0:  600\n",
      "Pred1:  2303 , Label1:  2307\n",
      "Pred0:  572 , Label0:  600\n",
      "Pred1:  949 , Label1:  941\n",
      "Pred0:  786 , Label0:  800\n",
      "Pred1:  998 , Label1:  1002\n",
      "Pred0:  380 , Label0:  400\n",
      "Pred1:  662 , Label1:  668\n",
      "Pred0:  390 , Label0:  400\n",
      "Pred1:  714 , Label1:  720\n",
      "Pred0:  559 , Label0:  600\n",
      "Pred1:  1095 , Label1:  1104\n",
      "Pred0:  574 , Label0:  600\n",
      "Pred1:  942 , Label1:  942\n",
      "Pred0:  583 , Label0:  600\n",
      "Pred1:  1263 , Label1:  1268\n",
      "Pred0:  713 , Label0:  700\n",
      "Pred1:  1056 , Label1:  1053\n",
      "Pred0:  386 , Label0:  400\n",
      "Pred1:  629 , Label1:  640\n",
      "Pred0:  879 , Label0:  900\n",
      "Pred1:  1291 , Label1:  1286\n",
      "Pred0:  894 , Label0:  900\n",
      "Pred1:  1399 , Label1:  1408\n",
      "Pred0:  596 , Label0:  600\n",
      "Pred1:  882 , Label1:  888\n",
      "Pred0:  900 , Label0:  900\n",
      "Pred1:  1633 , Label1:  1642\n",
      "Pred0:  514 , Label0:  500\n",
      "Pred1:  1046 , Label1:  1036\n",
      "Pred0:  782 , Label0:  800\n",
      "Pred1:  981 , Label1:  1003\n",
      "Pred0:  461 , Label0:  500\n",
      "Pred1:  806 , Label1:  813\n",
      "Pred0:  1751 , Label0:  700\n",
      "Pred1:  1823 , Label1:  1791\n",
      "Pred0:  890 , Label0:  900\n",
      "Pred1:  1564 , Label1:  1577\n",
      "Pred0:  486 , Label0:  500\n",
      "Pred1:  1643 , Label1:  1630\n",
      "Pred0:  478 , Label0:  500\n",
      "Pred1:  670 , Label1:  687\n",
      "Pred0:  850 , Label0:  800\n",
      "Pred1:  2083 , Label1:  2059\n",
      "Pred0:  498 , Label0:  500\n",
      "Pred1:  762 , Label1:  754\n",
      "Pred0:  692 , Label0:  700\n",
      "Pred1:  794 , Label1:  803\n",
      "Pred0:  898 , Label0:  900\n",
      "Pred1:  1444 , Label1:  1445\n",
      "Pred0:  600 , Label0:  600\n",
      "Pred1:  831 , Label1:  835\n",
      "Pred0:  594 , Label0:  601\n",
      "Pred1:  879 , Label1:  898\n",
      "Pred0:  688 , Label0:  700\n",
      "Pred1:  1443 , Label1:  1440\n",
      "Pred0:  696 , Label0:  700\n",
      "Pred1:  996 , Label1:  1000\n",
      "Pred0:  584 , Label0:  600\n",
      "Pred1:  853 , Label1:  859\n",
      "Pred0:  1175 , Label0:  600\n",
      "Pred1:  2559 , Label1:  2489\n",
      "Pred0:  593 , Label0:  599\n",
      "Pred1:  888 , Label1:  889\n",
      "Pred0:  878 , Label0:  900\n",
      "Pred1:  2195 , Label1:  2194\n",
      "Pred0:  828 , Label0:  800\n",
      "Pred1:  996 , Label1:  997\n",
      "Pred0:  471 , Label0:  400\n",
      "Pred1:  1591 , Label1:  1662\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  682 , Label1:  670\n",
      "Pred0:  890 , Label0:  900\n",
      "Pred1:  1163 , Label1:  1166\n",
      "Pred0:  896 , Label0:  902\n",
      "Pred1:  1186 , Label1:  1187\n",
      "Pred0:  696 , Label0:  700\n",
      "Pred1:  950 , Label1:  953\n",
      "Pred0:  668 , Label0:  700\n",
      "Pred1:  1915 , Label1:  1929\n",
      "Pred0:  516 , Label0:  500\n",
      "Pred1:  1118 , Label1:  1076\n",
      "Pred0:  506 , Label0:  500\n",
      "Pred1:  916 , Label1:  925\n",
      "Pred0:  794 , Label0:  800\n",
      "Pred1:  1160 , Label1:  1163\n",
      "Pred0:  447 , Label0:  500\n",
      "Pred1:  745 , Label1:  749\n",
      "Pred0:  886 , Label0:  900\n",
      "Pred1:  1363 , Label1:  1356\n",
      "Pred0:  890 , Label0:  900\n",
      "Pred1:  1126 , Label1:  1138\n",
      "Pred0:  479 , Label0:  500\n",
      "Pred1:  1318 , Label1:  1320\n",
      "Pred0:  800 , Label0:  800\n",
      "Pred1:  1623 , Label1:  1648\n",
      "Pred0:  570 , Label0:  600\n",
      "Pred1:  850 , Label1:  848\n",
      "Pred0:  392 , Label0:  400\n",
      "Pred1:  976 , Label1:  982\n",
      "Pred0:  894 , Label0:  900\n",
      "Pred1:  1154 , Label1:  1147\n",
      "Pred0:  400 , Label0:  399\n",
      "Pred1:  647 , Label1:  655\n",
      "Pred0:  774 , Label0:  800\n",
      "Pred1:  1694 , Label1:  1707\n",
      "Pred0:  397 , Label0:  400\n",
      "Pred1:  751 , Label1:  756\n",
      "Pred0:  497 , Label0:  500\n",
      "Pred1:  996 , Label1:  991\n",
      "Pred0:  504 , Label0:  500\n",
      "Pred1:  778 , Label1:  783\n",
      "Pred0:  478 , Label0:  499\n",
      "Pred1:  1007 , Label1:  1012\n",
      "Pred0:  582 , Label0:  600\n",
      "Pred1:  861 , Label1:  854\n",
      "Pred0:  894 , Label0:  900\n",
      "Pred1:  1087 , Label1:  1101\n",
      "Pred0:  906 , Label0:  900\n",
      "Pred1:  1022 , Label1:  1023\n",
      "Pred0:  796 , Label0:  800\n",
      "Pred1:  1063 , Label1:  1093\n",
      "Pred0:  890 , Label0:  901\n",
      "Pred1:  1060 , Label1:  1072\n",
      "Pred0:  698 , Label0:  700\n",
      "Pred1:  1571 , Label1:  1558\n",
      "Pred0:  685 , Label0:  700\n",
      "Pred1:  960 , Label1:  962\n",
      "Pred0:  468 , Label0:  500\n",
      "Pred1:  741 , Label1:  749\n",
      "Pred0:  755 , Label0:  800\n",
      "Pred1:  1423 , Label1:  1442\n",
      "Pred0:  778 , Label0:  800\n",
      "Pred1:  1411 , Label1:  1430\n",
      "Pred0:  609 , Label0:  600\n",
      "Pred1:  868 , Label1:  875\n",
      "Pred0:  594 , Label0:  600\n",
      "Pred1:  1096 , Label1:  1096\n",
      "Pred0:  673 , Label0:  700\n",
      "Pred1:  867 , Label1:  877\n",
      "Pred0:  786 , Label0:  800\n",
      "Pred1:  1174 , Label1:  1179\n",
      "Pred0:  687 , Label0:  700\n",
      "Pred1:  990 , Label1:  1006\n",
      "Pred0:  396 , Label0:  400\n",
      "Pred1:  662 , Label1:  661\n",
      "Pred0:  723 , Label0:  694\n",
      "Pred1:  2007 , Label1:  1992\n",
      "Pred0:  1434 , Label0:  500\n",
      "Pred1:  1611 , Label1:  1611\n",
      "Pred0:  4261 , Label0:  1000\n",
      "Pred1:  4815 , Label1:  4034\n",
      "Pred0:  1019 , Label0:  510\n",
      "Pred1:  1771 , Label1:  1747\n",
      "Pred0:  454 , Label0:  500\n",
      "Pred1:  1347 , Label1:  1346\n",
      "Pred0:  705 , Label0:  698\n",
      "Pred1:  1291 , Label1:  1320\n",
      "Pred0:  680 , Label0:  700\n",
      "Pred1:  1712 , Label1:  1686\n",
      "Pred0:  1585 , Label0:  1148\n",
      "Pred1:  1935 , Label1:  1701\n",
      "Pred0:  450 , Label0:  500\n",
      "Pred1:  1392 , Label1:  1397\n",
      "Pred0:  610 , Label0:  616\n",
      "Pred1:  951 , Label1:  951\n",
      "Pred0:  875 , Label0:  899\n",
      "Pred1:  1431 , Label1:  1424\n",
      "Pred0:  902 , Label0:  800\n",
      "Pred1:  3103 , Label1:  2981\n",
      "Pred0:  787 , Label0:  800\n",
      "Pred1:  1169 , Label1:  1173\n",
      "Pred0:  3563 , Label0:  400\n",
      "Pred1:  3679 , Label1:  3605\n",
      "Pred0:  687 , Label0:  700\n",
      "Pred1:  1875 , Label1:  1848\n",
      "Pred0:  902 , Label0:  900\n",
      "Pred1:  1190 , Label1:  1191\n",
      "Pred0:  600 , Label0:  600\n",
      "Pred1:  1180 , Label1:  1161\n",
      "Pred0:  681 , Label0:  700\n",
      "Pred1:  1123 , Label1:  1125\n",
      "Pred0:  662 , Label0:  701\n",
      "Pred1:  1190 , Label1:  1184\n",
      "Pred0:  470 , Label0:  500\n",
      "Pred1:  955 , Label1:  957\n",
      "Pred0:  610 , Label0:  600\n",
      "Pred1:  906 , Label1:  915\n",
      "Pred0:  499 , Label0:  500\n",
      "Pred1:  866 , Label1:  875\n",
      "Pred0:  894 , Label0:  900\n",
      "Pred1:  1086 , Label1:  1099\n",
      "Pred0:  925 , Label0:  900\n",
      "Pred1:  1199 , Label1:  1187\n",
      "Pred0:  604 , Label0:  600\n",
      "Pred1:  878 , Label1:  899\n",
      "Pred0:  781 , Label0:  800\n",
      "Pred1:  1283 , Label1:  1271\n",
      "Pred0:  394 , Label0:  401\n",
      "Pred1:  607 , Label1:  611\n",
      "Pred0:  759 , Label0:  800\n",
      "Pred1:  1880 , Label1:  1924\n",
      "Pred0:  392 , Label0:  399\n",
      "Pred1:  652 , Label1:  659\n",
      "Pred0:  678 , Label0:  700\n",
      "Pred1:  1670 , Label1:  1658\n",
      "Pred0:  476 , Label0:  500\n",
      "Pred1:  726 , Label1:  729\n",
      "Pred0:  887 , Label0:  900\n",
      "Pred1:  2375 , Label1:  2377\n",
      "Pred0:  499 , Label0:  501\n",
      "Pred1:  1669 , Label1:  1284\n",
      "Pred0:  897 , Label0:  900\n",
      "Pred1:  1159 , Label1:  1136\n",
      "Pred0:  706 , Label0:  700\n",
      "Pred1:  1863 , Label1:  1852\n",
      "Pred0:  679 , Label0:  692\n",
      "Pred1:  1663 , Label1:  1663\n",
      "Pred0:  664 , Label0:  700\n",
      "Pred1:  971 , Label1:  953\n",
      "Pred0:  878 , Label0:  900\n",
      "Pred1:  1100 , Label1:  1106\n",
      "Pred0:  967 , Label0:  900\n",
      "Pred1:  1415 , Label1:  3924\n",
      "Pred0:  601 , Label0:  598\n",
      "Pred1:  1523 , Label1:  1528\n",
      "Pred0:  796 , Label0:  800\n",
      "Pred1:  906 , Label1:  923\n",
      "Pred0:  566 , Label0:  600\n",
      "Pred1:  1611 , Label1:  1575\n",
      "Pred0:  462 , Label0:  500\n",
      "Pred1:  497 , Label1:  778\n",
      "Pred0:  386 , Label0:  400\n",
      "Pred1:  670 , Label1:  689\n",
      "Pred0:  434 , Label0:  501\n",
      "Pred1:  1454 , Label1:  1461\n",
      "Pred0:  590 , Label0:  601\n",
      "Pred1:  620 , Label1:  848\n",
      "Pred0:  584 , Label0:  600\n",
      "Pred1:  1275 , Label1:  1278\n",
      "Pred0:  459 , Label0:  700\n",
      "Pred1:  699 , Label1:  804\n",
      "Pred0:  592 , Label0:  600\n",
      "Pred1:  846 , Label1:  849\n",
      "Pred0:  707 , Label0:  700\n",
      "Pred1:  1199 , Label1:  1195\n",
      "Pred0:  802 , Label0:  800\n",
      "Pred1:  1815 , Label1:  1819\n",
      "Pred0:  1439 , Label0:  800\n",
      "Pred1:  2367 , Label1:  2383\n",
      "Pred0:  906 , Label0:  900\n",
      "Pred1:  1915 , Label1:  1920\n",
      "Pred0:  859 , Label0:  900\n",
      "Pred1:  1342 , Label1:  1334\n",
      "Pred0:  404 , Label0:  400\n",
      "Pred1:  518 , Label1:  540\n",
      "Pred0:  704 , Label0:  700\n",
      "Pred1:  1186 , Label1:  1186\n",
      "Pred0:  781 , Label0:  800\n",
      "Pred1:  1215 , Label1:  1193\n",
      "Pred0:  890 , Label0:  900\n",
      "Pred1:  1041 , Label1:  1040\n",
      "Pred0:  408 , Label0:  400\n",
      "Pred1:  598 , Label1:  608\n",
      "Pred0:  392 , Label0:  400\n",
      "Pred1:  654 , Label1:  670\n",
      "Pred0:  393 , Label0:  400\n",
      "Pred1:  905 , Label1:  1210\n",
      "Pred0:  572 , Label0:  600\n",
      "Pred1:  971 , Label1:  970\n",
      "Pred0:  863 , Label0:  900\n",
      "Pred1:  1651 , Label1:  1656\n",
      "Pred0:  679 , Label0:  700\n",
      "Pred1:  1439 , Label1:  1432\n",
      "Pred0:  474 , Label0:  500\n",
      "Pred1:  968 , Label1:  972\n",
      "Pred0:  401 , Label0:  400\n",
      "Pred1:  724 , Label1:  726\n",
      "Pred0:  394 , Label0:  401\n",
      "Pred1:  549 , Label1:  563\n",
      "Pred0:  538 , Label0:  600\n",
      "Pred1:  1183 , Label1:  1165\n",
      "Pred0:  1047 , Label0:  400\n",
      "Pred1:  2443 , Label1:  2360\n",
      "Pred0:  394 , Label0:  400\n",
      "Pred1:  942 , Label1:  962\n",
      "Pred0:  363 , Label0:  400\n",
      "Pred1:  1123 , Label1:  1117\n",
      "Pred0:  394 , Label0:  400\n",
      "Pred1:  903 , Label1:  902\n",
      "Pred0:  781 , Label0:  800\n",
      "Pred1:  1511 , Label1:  1513\n",
      "Pred0:  1421 , Label0:  500\n",
      "Pred1:  1461 , Label1:  1468\n",
      "Pred0:  498 , Label0:  500\n",
      "Pred1:  655 , Label1:  667\n",
      "Pred0:  575 , Label0:  600\n",
      "Pred1:  936 , Label1:  933\n",
      "Pred0:  798 , Label0:  800\n",
      "Pred1:  1502 , Label1:  1509\n",
      "Pred0:  781 , Label0:  800\n",
      "Pred1:  1175 , Label1:  1174\n",
      "Pred0:  780 , Label0:  800\n",
      "Pred1:  1317 , Label1:  1312\n",
      "Pred0:  496 , Label0:  500\n",
      "Pred1:  662 , Label1:  679\n",
      "Pred0:  408 , Label0:  397\n",
      "Pred1:  1655 , Label1:  1649\n",
      "Pred0:  781 , Label0:  800\n",
      "Pred1:  1030 , Label1:  1030\n",
      "Pred0:  786 , Label0:  800\n",
      "Pred1:  1054 , Label1:  1071\n",
      "Pred0:  411 , Label0:  400\n",
      "Pred1:  1643 , Label1:  1603\n",
      "Pred0:  694 , Label0:  700\n",
      "Pred1:  1603 , Label1:  1607\n",
      "Pred0:  822 , Label0:  800\n",
      "Pred1:  2051 , Label1:  2015\n",
      "Pred0:  500 , Label0:  500\n",
      "Pred1:  836 , Label1:  849\n",
      "Pred0:  778 , Label0:  800\n",
      "Pred1:  1355 , Label1:  1358\n",
      "Pred0:  394 , Label0:  400\n",
      "Pred1:  744 , Label1:  739\n",
      "Pred0:  578 , Label0:  600\n",
      "Pred1:  1034 , Label1:  1036\n",
      "Pred0:  647 , Label0:  600\n",
      "Pred1:  1779 , Label1:  1791\n",
      "Pred0:  386 , Label0:  400\n",
      "Pred1:  611 , Label1:  620\n",
      "Pred0:  697 , Label0:  683\n",
      "Pred1:  1671 , Label1:  1667\n",
      "Pred0:  698 , Label0:  700\n",
      "Pred1:  946 , Label1:  948\n",
      "Pred0:  802 , Label0:  800\n",
      "Pred1:  1830 , Label1:  1840\n",
      "Pred0:  698 , Label0:  700\n",
      "Pred1:  863 , Label1:  861\n",
      "Pred0:  588 , Label0:  600\n",
      "Pred1:  982 , Label1:  983\n",
      "Pred0:  600 , Label0:  600\n",
      "Pred1:  824 , Label1:  826\n",
      "Pred0:  498 , Label0:  499\n",
      "Pred1:  1006 , Label1:  999\n",
      "Pred0:  704 , Label0:  701\n",
      "Pred1:  1034 , Label1:  1047\n",
      "Pred0:  770 , Label0:  700\n",
      "Pred1:  1975 , Label1:  1928\n",
      "Pred0:  399 , Label0:  400\n",
      "Pred1:  678 , Label1:  687\n",
      "Pred0:  886 , Label0:  900\n",
      "Pred1:  1915 , Label1:  1943\n",
      "Pred0:  394 , Label0:  401\n",
      "Pred1:  510 , Label1:  515\n",
      "Pred0:  896 , Label0:  900\n",
      "Pred1:  1172 , Label1:  1190\n",
      "Pred0:  884 , Label0:  900\n",
      "Pred1:  2231 , Label1:  2236\n",
      "Pred0:  752 , Label0:  700\n",
      "Pred1:  1527 , Label1:  1544\n",
      "Pred0:  481 , Label0:  500\n",
      "Pred1:  668 , Label1:  676\n",
      "Pred0:  696 , Label0:  700\n",
      "Pred1:  835 , Label1:  841\n",
      "Pred0:  402 , Label0:  400\n",
      "Pred1:  837 , Label1:  842\n",
      "Pred0:  774 , Label0:  800\n",
      "Pred1:  1126 , Label1:  1132\n",
      "Pred0:  799 , Label0:  800\n",
      "Pred1:  1747 , Label1:  1766\n",
      "Pred0:  772 , Label0:  800\n",
      "Pred1:  1350 , Label1:  1342\n",
      "Pred0:  842 , Label0:  900\n",
      "Pred1:  1241 , Label1:  1233\n",
      "Pred0:  886 , Label0:  900\n",
      "Pred1:  1919 , Label1:  1947\n",
      "Pred0:  394 , Label0:  400\n",
      "Pred1:  670 , Label1:  678\n",
      "Pred0:  469 , Label0:  500\n",
      "Pred1:  773 , Label1:  831\n",
      "Pred0:  862 , Label0:  900\n",
      "Pred1:  1208 , Label1:  1210\n",
      "Pred0:  666 , Label0:  704\n",
      "Pred1:  1609 , Label1:  1624\n",
      "Pred0:  758 , Label0:  800\n",
      "Pred1:  1759 , Label1:  1747\n",
      "Pred0:  776 , Label0:  800\n",
      "Pred1:  1161 , Label1:  1172\n",
      "Pred0:  401 , Label0:  400\n",
      "Pred1:  1568 , Label1:  1553\n",
      "Pred0:  861 , Label0:  900\n",
      "Pred1:  1751 , Label1:  1757\n",
      "Pred0:  402 , Label0:  400\n",
      "Pred1:  930 , Label1:  968\n",
      "Pred0:  892 , Label0:  900\n",
      "Pred1:  1098 , Label1:  1108\n",
      "Pred0:  870 , Label0:  900\n",
      "Pred1:  1650 , Label1:  1655\n",
      "Pred0:  393 , Label0:  400\n",
      "Pred1:  699 , Label1:  703\n",
      "Pred0:  402 , Label0:  400\n",
      "Pred1:  847 , Label1:  843\n",
      "Pred0:  778 , Label0:  800\n",
      "Pred1:  1166 , Label1:  1161\n",
      "Pred0:  904 , Label0:  900\n",
      "Pred1:  1470 , Label1:  1460\n",
      "Pred0:  809 , Label0:  800\n",
      "Pred1:  2979 , Label1:  2940\n",
      "Pred0:  701 , Label0:  700\n",
      "Pred1:  1608 , Label1:  1613\n",
      "Pred0:  770 , Label0:  800\n",
      "Pred1:  1466 , Label1:  1475\n",
      "Pred0:  893 , Label0:  900\n",
      "Pred1:  1019 , Label1:  1019\n",
      "Pred0:  591 , Label0:  400\n",
      "Pred1:  3989 , Label1:  3929\n",
      "Pred0:  894 , Label0:  900\n",
      "Pred1:  1559 , Label1:  1547\n",
      "Pred0:  395 , Label0:  400\n",
      "Pred1:  1235 , Label1:  1235\n",
      "Pred0:  554 , Label0:  600\n",
      "Pred1:  1085 , Label1:  1083\n",
      "Pred0:  802 , Label0:  799\n",
      "Pred1:  1003 , Label1:  1007\n",
      "Pred0:  851 , Label0:  900\n",
      "Pred1:  2063 , Label1:  2080\n",
      "Pred0:  682 , Label0:  700\n",
      "Pred1:  1163 , Label1:  1186\n",
      "Pred0:  662 , Label0:  700\n",
      "Pred1:  1123 , Label1:  1108\n",
      "Pred0:  815 , Label0:  800\n",
      "Pred1:  2534 , Label1:  2545\n",
      "Pred0:  906 , Label0:  900\n",
      "Pred1:  1958 , Label1:  1956\n",
      "Pred0:  901 , Label0:  900\n",
      "Pred1:  1816 , Label1:  1830\n",
      "Pred0:  676 , Label0:  600\n",
      "Pred1:  1819 , Label1:  1812\n",
      "Pred0:  412 , Label0:  400\n",
      "Pred1:  1290 , Label1:  1249\n",
      "Pred0:  863 , Label0:  900\n",
      "Pred1:  1190 , Label1:  1190\n",
      "Pred0:  602 , Label0:  600\n",
      "Pred1:  894 , Label1:  893\n",
      "Pred0:  795 , Label0:  800\n",
      "Pred1:  1843 , Label1:  1852\n",
      "Pred0:  787 , Label0:  800\n",
      "Pred1:  1971 , Label1:  1956\n",
      "Pred0:  396 , Label0:  400\n",
      "Pred1:  644 , Label1:  645\n",
      "Pred0:  395 , Label0:  400\n",
      "Pred1:  1359 , Label1:  1365\n",
      "Pred0:  712 , Label0:  700\n",
      "Pred1:  1299 , Label1:  1296\n",
      "Pred0:  692 , Label0:  700\n",
      "Pred1:  972 , Label1:  986\n",
      "Pred0:  882 , Label0:  900\n",
      "Pred1:  1818 , Label1:  1817\n",
      "Pred0:  5 , Label0:  600\n",
      "Pred1:  593 , Label1:  697\n",
      "Pred0:  402 , Label0:  400\n",
      "Pred1:  1462 , Label1:  1464\n",
      "Pred0:  462 , Label0:  500\n",
      "Pred1:  1114 , Label1:  1112\n",
      "Pred0:  796 , Label0:  800\n",
      "Pred1:  912 , Label1:  924\n",
      "Pred0:  753 , Label0:  700\n",
      "Pred1:  1775 , Label1:  1768\n",
      "Pred0:  469 , Label0:  500\n",
      "Pred1:  1227 , Label1:  1229\n",
      "Pred0:  892 , Label0:  900\n",
      "Pred1:  1390 , Label1:  1397\n",
      "Pred0:  824 , Label0:  800\n",
      "Pred1:  918 , Label1:  924\n",
      "Pred0:  594 , Label0:  601\n",
      "Pred1:  860 , Label1:  863\n",
      "Pred0:  572 , Label0:  600\n",
      "Pred1:  943 , Label1:  944\n",
      "Pred0:  2042 , Label0:  500\n",
      "Pred1:  2319 , Label1:  2305\n",
      "Pred0:  905 , Label0:  900\n",
      "Pred1:  1507 , Label1:  1456\n",
      "Pred0:  814 , Label0:  800\n",
      "Pred1:  1640 , Label1:  1640\n",
      "Pred0:  702 , Label0:  700\n",
      "Pred1:  1142 , Label1:  1118\n",
      "Pred0:  409 , Label0:  400\n",
      "Pred1:  1523 , Label1:  1492\n",
      "Pred0:  459 , Label0:  500\n",
      "Pred1:  1246 , Label1:  1253\n",
      "Pred0:  890 , Label0:  901\n",
      "Pred1:  1042 , Label1:  1051\n",
      "Pred0:  396 , Label0:  400\n",
      "Pred1:  687 , Label1:  692\n",
      "Pred0:  882 , Label0:  900\n",
      "Pred1:  1317 , Label1:  1330\n",
      "Pred0:  894 , Label0:  897\n",
      "Pred1:  1971 , Label1:  1968\n",
      "Pred0:  490 , Label0:  499\n",
      "Pred1:  757 , Label1:  756\n",
      "Pred0:  694 , Label0:  700\n",
      "Pred1:  1491 , Label1:  1466\n",
      "Pred0:  798 , Label0:  800\n",
      "Pred1:  950 , Label1:  952\n",
      "Pred0:  496 , Label0:  500\n",
      "Pred1:  693 , Label1:  696\n",
      "Pred0:  977 , Label0:  900\n",
      "Pred1:  3031 , Label1:  3195\n",
      "Pred0:  692 , Label0:  700\n",
      "Pred1:  1082 , Label1:  1085\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  648 , Label1:  652\n",
      "Pred0:  886 , Label0:  900\n",
      "Pred1:  1247 , Label1:  1255\n",
      "Pred0:  815 , Label0:  800\n",
      "Pred1:  1303 , Label1:  1336\n",
      "Pred0:  891 , Label0:  900\n",
      "Pred1:  1125 , Label1:  1316\n",
      "Pred0:  484 , Label0:  501\n",
      "Pred1:  724 , Label1:  731\n",
      "Pred0:  712 , Label0:  700\n",
      "Pred1:  1499 , Label1:  1498\n",
      "Pred0:  433 , Label0:  499\n",
      "Pred1:  983 , Label1:  987\n",
      "Pred0:  898 , Label0:  884\n",
      "Pred1:  1782 , Label1:  1771\n",
      "Pred0:  800 , Label0:  800\n",
      "Pred1:  1348 , Label1:  1352\n",
      "Pred0:  499 , Label0:  501\n",
      "Pred1:  1551 , Label1:  1543\n",
      "Pred0:  682 , Label0:  700\n",
      "Pred1:  1263 , Label1:  1266\n",
      "Pred0:  861 , Label0:  800\n",
      "Pred1:  1939 , Label1:  1958\n",
      "Pred0:  701 , Label0:  600\n",
      "Pred1:  1365 , Label1:  1364\n",
      "Pred0:  498 , Label0:  500\n",
      "Pred1:  814 , Label1:  806\n",
      "Pred0:  762 , Label0:  800\n",
      "Pred1:  1655 , Label1:  1595\n",
      "Pred0:  507 , Label0:  500\n",
      "Pred1:  1163 , Label1:  1150\n",
      "Pred0:  898 , Label0:  900\n",
      "Pred1:  1471 , Label1:  1452\n",
      "Pred0:  754 , Label0:  800\n",
      "Pred1:  1799 , Label1:  1803\n",
      "Pred0:  562 , Label0:  599\n",
      "Pred1:  931 , Label1:  932\n",
      "Pred0:  893 , Label0:  900\n",
      "Pred1:  902 , Label1:  1109\n",
      "Pred0:  419 , Label0:  400\n",
      "Pred1:  1223 , Label1:  1186\n",
      "Pred0:  498 , Label0:  500\n",
      "Pred1:  942 , Label1:  955\n",
      "Pred0:  660 , Label0:  700\n",
      "Pred1:  1094 , Label1:  1093\n",
      "Pred0:  387 , Label0:  400\n",
      "Pred1:  1048 , Label1:  1051\n",
      "Pred0:  648 , Label0:  699\n",
      "Pred1:  885 , Label1:  892\n",
      "Pred0:  905 , Label0:  500\n",
      "Pred1:  1881 , Label1:  1902\n",
      "Pred0:  920 , Label0:  900\n",
      "Pred1:  1093 , Label1:  1100\n",
      "Pred0:  1105 , Label0:  500\n",
      "Pred1:  1623 , Label1:  1557\n",
      "Pred0:  886 , Label0:  900\n",
      "Pred1:  1494 , Label1:  1501\n",
      "Pred0:  594 , Label0:  600\n",
      "Pred1:  1507 , Label1:  1516\n",
      "Pred0:  847 , Label0:  900\n",
      "Pred1:  1931 , Label1:  1901\n",
      "Pred0:  902 , Label0:  900\n",
      "Pred1:  1274 , Label1:  1285\n",
      "Pred0:  548 , Label0:  600\n",
      "Pred1:  1454 , Label1:  1455\n",
      "Pred0:  492 , Label0:  500\n",
      "Pred1:  1064 , Label1:  1064\n",
      "Pred0:  802 , Label0:  800\n",
      "Pred1:  1116 , Label1:  1118\n",
      "Pred0:  763 , Label0:  700\n",
      "Pred1:  1839 , Label1:  1838\n",
      "Pred0:  476 , Label0:  480\n",
      "Pred1:  1326 , Label1:  1299\n",
      "Pred0:  913 , Label0:  900\n",
      "Pred1:  1771 , Label1:  1757\n",
      "Pred0:  452 , Label0:  500\n",
      "Pred1:  869 , Label1:  868\n",
      "Pred0:  806 , Label0:  800\n",
      "Pred1:  1816 , Label1:  1790\n",
      "Pred0:  726 , Label0:  700\n",
      "Pred1:  1363 , Label1:  1351\n",
      "Pred0:  794 , Label0:  800\n",
      "Pred1:  1048 , Label1:  1051\n",
      "Pred0:  496 , Label0:  500\n",
      "Pred1:  762 , Label1:  757\n",
      "Pred0:  787 , Label0:  800\n",
      "Pred1:  1870 , Label1:  1868\n",
      "Pred0:  833 , Label0:  800\n",
      "Pred1:  1843 , Label1:  1783\n",
      "Pred0:  583 , Label0:  600\n",
      "Pred1:  1663 , Label1:  1449\n",
      "Pred0:  686 , Label0:  700\n",
      "Pred1:  1103 , Label1:  1107\n",
      "Pred0:  603 , Label0:  600\n",
      "Pred1:  927 , Label1:  938\n",
      "Pred0:  5 , Label0:  900\n",
      "Pred1:  1063 , Label1:  1067\n",
      "Pred0:  2310 , Label0:  700\n",
      "Pred1:  2471 , Label1:  2322\n",
      "Pred0:  559 , Label0:  600\n",
      "Pred1:  1566 , Label1:  1556\n",
      "Pred0:  482 , Label0:  500\n",
      "Pred1:  1223 , Label1:  1259\n",
      "Pred0:  1025 , Label0:  700\n",
      "Pred1:  3087 , Label1:  3077\n",
      "Pred0:  790 , Label0:  800\n",
      "Pred1:  1080 , Label1:  1069\n",
      "Pred0:  610 , Label0:  600\n",
      "Pred1:  1151 , Label1:  1221\n",
      "Pred0:  592 , Label0:  600\n",
      "Pred1:  1163 , Label1:  1172\n",
      "Pred0:  866 , Label0:  900\n",
      "Pred1:  1451 , Label1:  1412\n",
      "Pred0:  392 , Label0:  399\n",
      "Pred1:  976 , Label1:  979\n",
      "Pred0:  680 , Label0:  703\n",
      "Pred1:  1045 , Label1:  1041\n",
      "Pred0:  907 , Label0:  900\n",
      "Pred1:  2003 , Label1:  2001\n",
      "Pred0:  558 , Label0:  600\n",
      "Pred1:  934 , Label1:  938\n",
      "Pred0:  699 , Label0:  700\n",
      "Pred1:  917 , Label1:  915\n",
      "Pred0:  613 , Label0:  600\n",
      "Pred1:  1422 , Label1:  1418\n",
      "Pred0:  771 , Label0:  800\n",
      "Pred1:  1158 , Label1:  1150\n",
      "Pred0:  490 , Label0:  507\n",
      "Pred1:  725 , Label1:  734\n",
      "Pred0:  574 , Label0:  599\n",
      "Pred1:  1211 , Label1:  1215\n",
      "Pred0:  757 , Label0:  800\n",
      "Pred1:  1821 , Label1:  1859\n",
      "Pred0:  401 , Label0:  400\n",
      "Pred1:  1081 , Label1:  1189\n",
      "Pred0:  550 , Label0:  500\n",
      "Pred1:  1067 , Label1:  1070\n",
      "Pred0:  391 , Label0:  390\n",
      "Pred1:  1027 , Label1:  1022\n",
      "Pred0:  896 , Label0:  900\n",
      "Pred1:  1959 , Label1:  1928\n",
      "Pred0:  392 , Label0:  400\n",
      "Pred1:  1026 , Label1:  1032\n",
      "Pred0:  1745 , Label0:  800\n",
      "Pred1:  1899 , Label1:  1898\n",
      "Pred0:  466 , Label0:  500\n",
      "Pred1:  714 , Label1:  711\n",
      "Pred0:  558 , Label0:  600\n",
      "Pred1:  1168 , Label1:  1160\n",
      "Pred0:  686 , Label0:  700\n",
      "Pred1:  1111 , Label1:  1115\n",
      "Pred0:  690 , Label0:  700\n",
      "Pred1:  921 , Label1:  918\n",
      "Pred0:  784 , Label0:  800\n",
      "Pred1:  1583 , Label1:  1591\n",
      "Pred0:  394 , Label0:  398\n",
      "Pred1:  805 , Label1:  809\n",
      "Pred0:  748 , Label0:  800\n",
      "Pred1:  1566 , Label1:  1556\n",
      "Pred0:  453 , Label0:  500\n",
      "Pred1:  1109 , Label1:  1075\n",
      "Pred0:  1005 , Label0:  600\n",
      "Pred1:  1928 , Label1:  1916\n",
      "Pred0:  894 , Label0:  900\n",
      "Pred1:  1652 , Label1:  1659\n",
      "Pred0:  805 , Label0:  809\n",
      "Pred1:  1323 , Label1:  1307\n",
      "Pred0:  300 , Label0:  400\n",
      "Pred1:  1395 , Label1:  1392\n",
      "Pred0:  712 , Label0:  698\n",
      "Pred1:  1859 , Label1:  1848\n",
      "Pred0:  704 , Label0:  700\n",
      "Pred1:  1211 , Label1:  1205\n",
      "Pred0:  700 , Label0:  700\n",
      "Pred1:  863 , Label1:  855\n",
      "Pred0:  391 , Label0:  400\n",
      "Pred1:  710 , Label1:  710\n",
      "Pred0:  2738 , Label0:  900\n",
      "Pred1:  3215 , Label1:  3212\n",
      "Pred0:  4892 , Label0:  400\n",
      "Pred1:  5152 , Label1:  960\n",
      "Pred0:  1094 , Label0:  500\n",
      "Pred1:  2471 , Label1:  2456\n",
      "Pred0:  572 , Label0:  600\n",
      "Pred1:  773 , Label1:  784\n",
      "Pred0:  887 , Label0:  900\n",
      "Pred1:  4675 , Label1:  1349\n",
      "Pred0:  864 , Label0:  900\n",
      "Pred1:  1156 , Label1:  1157\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  786 , Label1:  791\n",
      "Pred0:  798 , Label0:  800\n",
      "Pred1:  1251 , Label1:  1273\n",
      "Pred0:  780 , Label0:  800\n",
      "Pred1:  1695 , Label1:  1683\n",
      "Pred0:  802 , Label0:  800\n",
      "Pred1:  954 , Label1:  972\n",
      "Pred0:  386 , Label0:  400\n",
      "Pred1:  637 , Label1:  654\n",
      "Pred0:  882 , Label0:  900\n",
      "Pred1:  1724 , Label1:  1720\n",
      "Pred0:  890 , Label0:  900\n",
      "Pred1:  1241 , Label1:  1210\n",
      "Pred0:  655 , Label0:  700\n",
      "Pred1:  1547 , Label1:  1527\n",
      "Pred0:  395 , Label0:  400\n",
      "Pred1:  911 , Label1:  929\n",
      "Pred0:  708 , Label0:  696\n",
      "Pred1:  2035 , Label1:  2043\n",
      "Pred0:  750 , Label0:  800\n",
      "Pred1:  1643 , Label1:  1661\n",
      "Pred0:  753 , Label0:  800\n",
      "Pred1:  1629 , Label1:  1715\n",
      "Pred0:  669 , Label0:  698\n",
      "Pred1:  1199 , Label1:  1202\n",
      "Pred0:  866 , Label0:  882\n",
      "Pred1:  913 , Label1:  989\n",
      "Pred0:  1147 , Label0:  700\n",
      "Pred1:  3037 , Label1:  3032\n",
      "Pred0:  794 , Label0:  800\n",
      "Pred1:  1078 , Label1:  1084\n",
      "Pred0:  1611 , Label0:  600\n",
      "Pred1:  2519 , Label1:  2493\n",
      "Pred0:  559 , Label0:  600\n",
      "Pred1:  1235 , Label1:  1239\n",
      "Pred0:  774 , Label0:  772\n",
      "Pred1:  2119 , Label1:  2280\n",
      "Pred0:  447 , Label0:  400\n",
      "Pred1:  1123 , Label1:  1142\n",
      "Pred0:  398 , Label0:  400\n",
      "Pred1:  1362 , Label1:  1366\n",
      "Pred0:  896 , Label0:  900\n",
      "Pred1:  1748 , Label1:  1763\n",
      "Pred0:  906 , Label0:  905\n",
      "Pred1:  1459 , Label1:  1455\n",
      "Pred0:  794 , Label0:  800\n",
      "Pred1:  1054 , Label1:  1061\n",
      "Pred0:  395 , Label0:  400\n",
      "Pred1:  1431 , Label1:  1444\n",
      "Pred0:  713 , Label0:  600\n",
      "Pred1:  1847 , Label1:  1837\n",
      "Pred0:  623 , Label0:  600\n",
      "Pred1:  1826 , Label1:  1824\n",
      "Pred0:  562 , Label0:  600\n",
      "Pred1:  952 , Label1:  954\n",
      "Pred0:  398 , Label0:  400\n",
      "Pred1:  565 , Label1:  556\n",
      "Pred0:  494 , Label0:  500\n",
      "Pred1:  840 , Label1:  843\n",
      "Pred0:  386 , Label0:  400\n",
      "Pred1:  650 , Label1:  664\n",
      "Pred0:  698 , Label0:  700\n",
      "Pred1:  822 , Label1:  823\n",
      "Pred0:  898 , Label0:  901\n",
      "Pred1:  1340 , Label1:  1345\n",
      "Pred0:  794 , Label0:  800\n",
      "Pred1:  1196 , Label1:  1206\n",
      "Pred0:  880 , Label0:  900\n",
      "Pred1:  1407 , Label1:  1427\n",
      "Pred0:  672 , Label0:  700\n",
      "Pred1:  873 , Label1:  871\n",
      "Pred0:  902 , Label0:  900\n",
      "Pred1:  1523 , Label1:  1524\n",
      "Pred0:  560 , Label0:  600\n",
      "Pred1:  1032 , Label1:  1041\n",
      "Pred0:  657 , Label0:  698\n",
      "Pred1:  1379 , Label1:  1375\n",
      "Pred0:  880 , Label0:  900\n",
      "Pred1:  1843 , Label1:  1808\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  748 , Label1:  759\n",
      "Pred0:  898 , Label0:  900\n",
      "Pred1:  1142 , Label1:  1141\n",
      "Pred0:  570 , Label0:  600\n",
      "Pred1:  895 , Label1:  901\n",
      "Pred0:  406 , Label0:  400\n",
      "Pred1:  583 , Label1:  605\n",
      "Pred0:  797 , Label0:  794\n",
      "Pred1:  1147 , Label1:  1153\n",
      "Pred0:  680 , Label0:  700\n",
      "Pred1:  1471 , Label1:  1480\n",
      "Pred0:  690 , Label0:  700\n",
      "Pred1:  958 , Label1:  952\n",
      "Pred0:  898 , Label0:  900\n",
      "Pred1:  2002 , Label1:  1997\n",
      "Pred0:  1677 , Label0:  800\n",
      "Pred1:  2682 , Label1:  1691\n",
      "Pred0:  802 , Label0:  800\n",
      "Pred1:  1287 , Label1:  1289\n",
      "Pred0:  469 , Label0:  500\n",
      "Pred1:  535 , Label1:  673\n",
      "Pred0:  888 , Label0:  899\n",
      "Pred1:  1180 , Label1:  1195\n",
      "Pred0:  590 , Label0:  600\n",
      "Pred1:  893 , Label1:  892\n",
      "Pred0:  776 , Label0:  800\n",
      "Pred1:  1807 , Label1:  1805\n",
      "Pred0:  496 , Label0:  500\n",
      "Pred1:  660 , Label1:  669\n",
      "Pred0:  456 , Label0:  497\n",
      "Pred1:  850 , Label1:  855\n",
      "Pred0:  504 , Label0:  500\n",
      "Pred1:  911 , Label1:  895\n",
      "Pred0:  770 , Label0:  800\n",
      "Pred1:  1879 , Label1:  1896\n",
      "Pred0:  715 , Label0:  700\n",
      "Pred1:  1959 , Label1:  1941\n",
      "Pred0:  588 , Label0:  600\n",
      "Pred1:  890 , Label1:  888\n",
      "Pred0:  499 , Label0:  494\n",
      "Pred1:  891 , Label1:  876\n",
      "Pred0:  802 , Label0:  800\n",
      "Pred1:  974 , Label1:  972\n",
      "Pred0:  690 , Label0:  700\n",
      "Pred1:  990 , Label1:  999\n",
      "Pred0:  482 , Label0:  500\n",
      "Pred1:  1411 , Label1:  1414\n",
      "Pred0:  1602 , Label0:  1000\n",
      "Pred1:  1942 , Label1:  1952\n",
      "Pred0:  1643 , Label0:  800\n",
      "Pred1:  1943 , Label1:  1941\n",
      "Pred0:  879 , Label0:  900\n",
      "Pred1:  1341 , Label1:  1349\n",
      "Pred0:  707 , Label0:  700\n",
      "Pred1:  1799 , Label1:  1772\n",
      "Pred0:  886 , Label0:  900\n",
      "Pred1:  1142 , Label1:  1144\n",
      "Pred0:  795 , Label0:  800\n",
      "Pred1:  1999 , Label1:  1993\n",
      "Pred0:  698 , Label0:  700\n",
      "Pred1:  964 , Label1:  968\n",
      "Pred0:  898 , Label0:  901\n",
      "Pred1:  1471 , Label1:  1404\n",
      "Pred0:  863 , Label0:  898\n",
      "Pred1:  2351 , Label1:  2345\n",
      "Pred0:  650 , Label0:  695\n",
      "Pred1:  1597 , Label1:  1595\n",
      "Pred0:  819 , Label0:  800\n",
      "Pred1:  1711 , Label1:  1716\n",
      "Pred0:  450 , Label0:  504\n",
      "Pred1:  1587 , Label1:  1545\n",
      "Pred0:  702 , Label0:  700\n",
      "Pred1:  901 , Label1:  910\n",
      "Pred0:  689 , Label0:  700\n",
      "Pred1:  1295 , Label1:  1310\n",
      "Pred0:  750 , Label0:  800\n",
      "Pred1:  1555 , Label1:  1574\n",
      "Pred0:  1214 , Label0:  900\n",
      "Pred1:  1667 , Label1:  1665\n",
      "Pred0:  707 , Label0:  700\n",
      "Pred1:  964 , Label1:  948\n",
      "Pred0:  778 , Label0:  800\n",
      "Pred1:  1029 , Label1:  1027\n",
      "Pred0:  656 , Label0:  697\n",
      "Pred1:  1125 , Label1:  1128\n",
      "Pred0:  571 , Label0:  400\n",
      "Pred1:  1331 , Label1:  1345\n",
      "Pred0:  394 , Label0:  400\n",
      "Pred1:  955 , Label1:  978\n",
      "Pred0:  896 , Label0:  900\n",
      "Pred1:  1007 , Label1:  1018\n",
      "Pred0:  389 , Label0:  390\n",
      "Pred1:  1083 , Label1:  1084\n",
      "Pred0:  794 , Label0:  799\n",
      "Pred1:  1100 , Label1:  1113\n",
      "Pred0:  647 , Label0:  600\n",
      "Pred1:  1347 , Label1:  1351\n",
      "Pred0:  892 , Label0:  900\n",
      "Pred1:  1755 , Label1:  1765\n",
      "Pred0:  793 , Label0:  800\n",
      "Pred1:  1036 , Label1:  1045\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  676 , Label1:  695\n",
      "Pred0:  696 , Label0:  700\n",
      "Pred1:  1030 , Label1:  1031\n",
      "Pred0:  392 , Label0:  400\n",
      "Pred1:  907 , Label1:  904\n",
      "Pred0:  695 , Label0:  700\n",
      "Pred1:  1443 , Label1:  1441\n",
      "Pred0:  816 , Label0:  800\n",
      "Pred1:  1967 , Label1:  1928\n",
      "Pred0:  592 , Label0:  600\n",
      "Pred1:  942 , Label1:  972\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  878 , Label1:  887\n",
      "Pred0:  685 , Label0:  700\n",
      "Pred1:  1663 , Label1:  1644\n",
      "Pred0:  496 , Label0:  499\n",
      "Pred1:  764 , Label1:  760\n",
      "Pred0:  482 , Label0:  500\n",
      "Pred1:  767 , Label1:  780\n",
      "Pred0:  402 , Label0:  400\n",
      "Pred1:  597 , Label1:  604\n",
      "Pred0:  575 , Label0:  600\n",
      "Pred1:  1582 , Label1:  1583\n",
      "Pred0:  727 , Label0:  801\n",
      "Pred1:  1332 , Label1:  1328\n",
      "Pred0:  777 , Label0:  800\n",
      "Pred1:  1595 , Label1:  1598\n",
      "Pred0:  507 , Label0:  500\n",
      "Pred1:  1591 , Label1:  1607\n",
      "Pred0:  698 , Label0:  700\n",
      "Pred1:  974 , Label1:  979\n",
      "Pred0:  391 , Label0:  400\n",
      "Pred1:  1167 , Label1:  1171\n",
      "Pred0:  490 , Label0:  500\n",
      "Pred1:  694 , Label1:  698\n",
      "Pred0:  891 , Label0:  900\n",
      "Pred1:  1268 , Label1:  1267\n",
      "Pred0:  601 , Label0:  600\n",
      "Pred1:  2524 , Label1:  2470\n",
      "Pred0:  454 , Label0:  500\n",
      "Pred1:  914 , Label1:  908\n",
      "Pred0:  1453 , Label0:  900\n",
      "Pred1:  2067 , Label1:  2065\n",
      "Pred0:  388 , Label0:  400\n",
      "Pred1:  791 , Label1:  805\n",
      "Pred0:  578 , Label0:  600\n",
      "Pred1:  1251 , Label1:  1257\n",
      "Pred0:  882 , Label0:  893\n",
      "Pred1:  1814 , Label1:  1812\n",
      "Pred0:  581 , Label0:  600\n",
      "Pred1:  610 , Label1:  853\n",
      "Pred0:  896 , Label0:  900\n",
      "Pred1:  1396 , Label1:  1412\n",
      "Pred0:  680 , Label0:  700\n",
      "Pred1:  1683 , Label1:  1689\n",
      "Pred0:  390 , Label0:  400\n",
      "Pred1:  702 , Label1:  707\n",
      "Pred0:  531 , Label0:  500\n",
      "Pred1:  1603 , Label1:  1656\n",
      "Pred0:  438 , Label0:  400\n",
      "Pred1:  1747 , Label1:  1737\n",
      "Pred0:  1445 , Label0:  800\n",
      "Pred1:  3505 , Label1:  3361\n",
      "Pred0:  560 , Label0:  500\n",
      "Pred1:  1477 , Label1:  1494\n",
      "Pred0:  768 , Label0:  800\n",
      "Pred1:  998 , Label1:  1000\n",
      "Pred0:  474 , Label0:  500\n",
      "Pred1:  891 , Label1:  888\n",
      "Pred0:  478 , Label0:  500\n",
      "Pred1:  2055 , Label1:  2039\n",
      "Pred0:  698 , Label0:  700\n",
      "Pred1:  944 , Label1:  950\n",
      "Pred0:  906 , Label0:  900\n",
      "Pred1:  1559 , Label1:  1545\n",
      "Pred0:  870 , Label0:  900\n",
      "Pred1:  2227 , Label1:  2219\n",
      "Pred0:  390 , Label0:  400\n",
      "Pred1:  754 , Label1:  759\n",
      "Pred0:  386 , Label0:  400\n",
      "Pred1:  607 , Label1:  585\n",
      "Pred0:  494 , Label0:  500\n",
      "Pred1:  642 , Label1:  648\n",
      "Pred0:  587 , Label0:  599\n",
      "Pred1:  811 , Label1:  820\n",
      "Pred0:  890 , Label0:  900\n",
      "Pred1:  1786 , Label1:  1793\n",
      "Pred0:  402 , Label0:  400\n",
      "Pred1:  1275 , Label1:  1263\n",
      "Pred0:  804 , Label0:  800\n",
      "Pred1:  1018 , Label1:  1030\n",
      "Pred0:  440 , Label0:  500\n",
      "Pred1:  999 , Label1:  979\n",
      "Pred0:  401 , Label0:  400\n",
      "Pred1:  693 , Label1:  721\n",
      "Pred0:  576 , Label0:  600\n",
      "Pred1:  995 , Label1:  1004\n",
      "Pred0:  490 , Label0:  500\n",
      "Pred1:  1413 , Label1:  1430\n",
      "Pred0:  436 , Label0:  500\n",
      "Pred1:  887 , Label1:  894\n",
      "Pred0:  611 , Label0:  600\n",
      "Pred1:  1743 , Label1:  1726\n",
      "Pred0:  594 , Label0:  601\n",
      "Pred1:  1103 , Label1:  1113\n",
      "Pred0:  958 , Label0:  900\n",
      "Pred1:  1109 , Label1:  1121\n",
      "Pred0:  391 , Label0:  399\n",
      "Pred1:  731 , Label1:  738\n",
      "Pred0:  794 , Label0:  801\n",
      "Pred1:  1419 , Label1:  1431\n",
      "Pred0:  899 , Label0:  900\n",
      "Pred1:  1828 , Label1:  1823\n",
      "Pred0:  464 , Label0:  500\n",
      "Pred1:  1307 , Label1:  1337\n",
      "Pred0:  881 , Label0:  860\n",
      "Pred1:  1904 , Label1:  1900\n",
      "Pred0:  1225 , Label0:  600\n",
      "Pred1:  1779 , Label1:  1744\n",
      "Pred0:  800 , Label0:  800\n",
      "Pred1:  1070 , Label1:  1075\n",
      "Pred0:  751 , Label0:  800\n",
      "Pred1:  1654 , Label1:  1651\n",
      "Pred0:  474 , Label0:  500\n",
      "Pred1:  1461 , Label1:  1467\n",
      "Pred0:  602 , Label0:  600\n",
      "Pred1:  787 , Label1:  785\n",
      "Pred0:  580 , Label0:  600\n",
      "Pred1:  805 , Label1:  819\n",
      "Pred0:  521 , Label0:  488\n",
      "Pred1:  1092 , Label1:  1084\n",
      "Pred0:  897 , Label0:  900\n",
      "Pred1:  1442 , Label1:  1410\n",
      "Pred0:  879 , Label0:  900\n",
      "Pred1:  1819 , Label1:  1823\n",
      "Pred0:  398 , Label0:  400\n",
      "Pred1:  1151 , Label1:  1150\n",
      "Pred0:  786 , Label0:  800\n",
      "Pred1:  1142 , Label1:  1147\n",
      "Pred0:  685 , Label0:  700\n",
      "Pred1:  3871 , Label1:  3833\n",
      "Pred0:  806 , Label0:  800\n",
      "Pred1:  1460 , Label1:  1456\n",
      "Pred0:  456 , Label0:  500\n",
      "Pred1:  872 , Label1:  874\n",
      "Pred0:  550 , Label0:  600\n",
      "Pred1:  1222 , Label1:  1224\n",
      "Pred0:  983 , Label0:  595\n",
      "Pred1:  1303 , Label1:  1305\n",
      "Pred0:  694 , Label0:  700\n",
      "Pred1:  1024 , Label1:  1031\n",
      "Pred0:  710 , Label0:  700\n",
      "Pred1:  1195 , Label1:  1179\n",
      "Pred0:  902 , Label0:  890\n",
      "Pred1:  2047 , Label1:  2033\n",
      "Pred0:  766 , Label0:  795\n",
      "Pred1:  1448 , Label1:  1448\n",
      "Pred0:  598 , Label0:  600\n",
      "Pred1:  904 , Label1:  907\n",
      "Pred0:  654 , Label0:  700\n",
      "Pred1:  1291 , Label1:  1280\n",
      "Pred0:  1176 , Label0:  600\n",
      "Pred1:  2989 , Label1:  3026\n",
      "Pred0:  892 , Label0:  900\n",
      "Pred1:  1012 , Label1:  1019\n",
      "Pred0:  700 , Label0:  700\n",
      "Pred1:  1110 , Label1:  1097\n",
      "Pred0:  598 , Label0:  600\n",
      "Pred1:  931 , Label1:  938\n",
      "Pred0:  882 , Label0:  900\n",
      "Pred1:  1803 , Label1:  1774\n",
      "Pred0:  779 , Label0:  800\n",
      "Pred1:  1627 , Label1:  1612\n",
      "Pred0:  556 , Label0:  600\n",
      "Pred1:  844 , Label1:  849\n",
      "Pred0:  408 , Label0:  400\n",
      "Pred1:  1015 , Label1:  1016\n",
      "Pred0:  896 , Label0:  901\n",
      "Pred1:  1030 , Label1:  1037\n",
      "Pred0:  905 , Label0:  900\n",
      "Pred1:  1004 , Label1:  1011\n",
      "Pred0:  783 , Label0:  800\n",
      "Pred1:  1061 , Label1:  1055\n",
      "Pred0:  684 , Label0:  700\n",
      "Pred1:  1755 , Label1:  1751\n",
      "Pred0:  602 , Label0:  602\n",
      "Pred1:  1551 , Label1:  1559\n",
      "Pred0:  610 , Label0:  600\n",
      "Pred1:  858 , Label1:  872\n",
      "Pred0:  802 , Label0:  807\n",
      "Pred1:  1419 , Label1:  1423\n",
      "Pred0:  876 , Label0:  900\n",
      "Pred1:  1531 , Label1:  1532\n",
      "Pred0:  658 , Label0:  700\n",
      "Pred1:  1539 , Label1:  1540\n",
      "Pred0:  397 , Label0:  397\n",
      "Pred1:  885 , Label1:  886\n",
      "Pred0:  510 , Label0:  500\n",
      "Pred1:  1354 , Label1:  1348\n",
      "Pred0:  780 , Label0:  800\n",
      "Pred1:  1471 , Label1:  1472\n",
      "Pred0:  579 , Label0:  600\n",
      "Pred1:  1635 , Label1:  1639\n",
      "Pred0:  566 , Label0:  600\n",
      "Pred1:  1178 , Label1:  1169\n",
      "Pred0:  476 , Label0:  500\n",
      "Pred1:  1779 , Label1:  1782\n",
      "Pred0:  600 , Label0:  599\n",
      "Pred1:  1266 , Label1:  1271\n",
      "Pred0:  787 , Label0:  797\n",
      "Pred1:  1851 , Label1:  1823\n",
      "Pred0:  682 , Label0:  700\n",
      "Pred1:  1496 , Label1:  1498\n",
      "Pred0:  507 , Label0:  500\n",
      "Pred1:  1350 , Label1:  1354\n",
      "Pred0:  564 , Label0:  600\n",
      "Pred1:  968 , Label1:  966\n",
      "Pred0:  4597 , Label0:  600\n",
      "Pred1:  1319 , Label1:  1347\n",
      "Pred0:  879 , Label0:  800\n",
      "Pred1:  2163 , Label1:  2127\n",
      "Pred0:  468 , Label0:  500\n",
      "Pred1:  498 , Label1:  756\n",
      "Pred0:  384 , Label0:  400\n",
      "Pred1:  647 , Label1:  662\n",
      "Pred0:  690 , Label0:  700\n",
      "Pred1:  1294 , Label1:  1293\n",
      "Pred0:  402 , Label0:  400\n",
      "Pred1:  1475 , Label1:  1460\n",
      "Pred0:  399 , Label0:  400\n",
      "Pred1:  596 , Label1:  601\n",
      "Pred0:  694 , Label0:  700\n",
      "Pred1:  838 , Label1:  848\n",
      "Pred0:  599 , Label0:  500\n",
      "Pred1:  1607 , Label1:  1671\n",
      "Pred0:  512 , Label0:  500\n",
      "Pred1:  1686 , Label1:  1686\n",
      "Pred0:  582 , Label0:  600\n",
      "Pred1:  784 , Label1:  796\n",
      "Pred0:  460 , Label0:  500\n",
      "Pred1:  771 , Label1:  767\n",
      "Pred0:  803 , Label0:  800\n",
      "Pred1:  1795 , Label1:  1750\n",
      "Pred0:  458 , Label0:  500\n",
      "Pred1:  835 , Label1:  842\n",
      "Pred0:  584 , Label0:  600\n",
      "Pred1:  863 , Label1:  866\n",
      "Pred0:  551 , Label0:  599\n",
      "Pred1:  1023 , Label1:  1053\n",
      "Pred0:  608 , Label0:  600\n",
      "Pred1:  850 , Label1:  858\n",
      "Pred0:  694 , Label0:  699\n",
      "Pred1:  900 , Label1:  889\n",
      "Pred0:  583 , Label0:  495\n",
      "Pred1:  963 , Label1:  969\n",
      "Pred0:  545 , Label0:  500\n",
      "Pred1:  1119 , Label1:  1097\n",
      "Pred0:  784 , Label0:  800\n",
      "Pred1:  1407 , Label1:  1445\n",
      "Pred0:  701 , Label0:  700\n",
      "Pred1:  1156 , Label1:  1152\n",
      "Pred0:  773 , Label0:  800\n",
      "Pred1:  2199 , Label1:  2235\n",
      "Pred0:  658 , Label0:  600\n",
      "Pred1:  1713 , Label1:  1695\n",
      "Pred0:  395 , Label0:  400\n",
      "Pred1:  1115 , Label1:  1129\n",
      "Pred0:  570 , Label0:  600\n",
      "Pred1:  975 , Label1:  992\n",
      "Pred0:  688 , Label0:  700\n",
      "Pred1:  965 , Label1:  968\n",
      "Pred0:  474 , Label0:  500\n",
      "Pred1:  1230 , Label1:  1236\n",
      "Pred0:  779 , Label0:  800\n",
      "Pred1:  1679 , Label1:  1673\n",
      "Pred0:  704 , Label0:  700\n",
      "Pred1:  968 , Label1:  966\n",
      "Pred0:  845 , Label0:  402\n",
      "Pred1:  1387 , Label1:  1392\n",
      "Pred0:  389 , Label0:  400\n",
      "Pred1:  438 , Label1:  729\n",
      "Pred0:  819 , Label0:  800\n",
      "Pred1:  1879 , Label1:  4036\n",
      "Pred0:  898 , Label0:  900\n",
      "Pred1:  1770 , Label1:  1766\n",
      "Pred0:  797 , Label0:  800\n",
      "Pred1:  1471 , Label1:  1502\n",
      "Pred0:  587 , Label0:  600\n",
      "Pred1:  1657 , Label1:  1629\n",
      "Pred0:  787 , Label0:  801\n",
      "Pred1:  950 , Label1:  960\n",
      "Pred0:  890 , Label0:  900\n",
      "Pred1:  1080 , Label1:  1091\n",
      "Pred0:  648 , Label0:  700\n",
      "Pred1:  1354 , Label1:  1353\n",
      "Pred0:  910 , Label0:  900\n",
      "Pred1:  971 , Label1:  1061\n",
      "Pred0:  688 , Label0:  700\n",
      "Pred1:  726 , Label1:  811\n",
      "Pred0:  591 , Label0:  598\n",
      "Pred1:  2039 , Label1:  2039\n",
      "Pred0:  773 , Label0:  800\n",
      "Pred1:  1112 , Label1:  1111\n",
      "Pred0:  667 , Label0:  600\n",
      "Pred1:  1315 , Label1:  1309\n",
      "Pred0:  490 , Label0:  500\n",
      "Pred1:  702 , Label1:  704\n",
      "Pred0:  892 , Label0:  900\n",
      "Pred1:  1158 , Label1:  1159\n",
      "Pred0:  792 , Label0:  800\n",
      "Pred1:  998 , Label1:  1013\n",
      "Pred0:  451 , Label0:  400\n",
      "Pred1:  1477 , Label1:  1439\n",
      "Pred0:  664 , Label0:  700\n",
      "Pred1:  1614 , Label1:  1632\n",
      "Pred0:  702 , Label0:  700\n",
      "Pred1:  966 , Label1:  968\n",
      "Pred0:  673 , Label0:  700\n",
      "Pred1:  1263 , Label1:  1252\n",
      "Pred0:  531 , Label0:  500\n",
      "Pred1:  1567 , Label1:  1552\n",
      "Pred0:  896 , Label0:  900\n",
      "Pred1:  1100 , Label1:  1095\n",
      "Pred0:  885 , Label0:  900\n",
      "Pred1:  1104 , Label1:  1112\n",
      "Pred0:  760 , Label0:  800\n",
      "Pred1:  1845 , Label1:  1480\n",
      "Pred0:  683 , Label0:  700\n",
      "Pred1:  1562 , Label1:  1564\n",
      "Pred0:  476 , Label0:  500\n",
      "Pred1:  1550 , Label1:  1547\n",
      "Pred0:  389 , Label0:  400\n",
      "Pred1:  907 , Label1:  899\n",
      "Pred0:  866 , Label0:  900\n",
      "Pred1:  1304 , Label1:  1309\n",
      "Pred0:  390 , Label0:  395\n",
      "Pred1:  731 , Label1:  753\n",
      "Pred0:  692 , Label0:  700\n",
      "Pred1:  1034 , Label1:  1046\n",
      "Pred0:  901 , Label0:  900\n",
      "Pred1:  1227 , Label1:  1233\n",
      "Pred0:  920 , Label0:  924\n",
      "Pred1:  1096 , Label1:  1083\n",
      "Pred0:  581 , Label0:  600\n",
      "Pred1:  1283 , Label1:  1313\n",
      "Pred0:  913 , Label0:  900\n",
      "Pred1:  1707 , Label1:  1746\n",
      "Pred0:  1037 , Label0:  400\n",
      "Pred1:  2701 , Label1:  2690\n",
      "Pred0:  466 , Label0:  499\n",
      "Pred1:  501 , Label1:  708\n",
      "Pred0:  1805 , Label0:  1000\n",
      "Pred1:  2659 , Label1:  2678\n",
      "Pred0:  613 , Label0:  602\n",
      "Pred1:  1006 , Label1:  1008\n",
      "Pred0:  573 , Label0:  600\n",
      "Pred1:  953 , Label1:  961\n",
      "Pred0:  396 , Label0:  400\n",
      "Pred1:  792 , Label1:  791\n",
      "Pred0:  378 , Label0:  400\n",
      "Pred1:  405 , Label1:  895\n",
      "Pred0:  796 , Label0:  800\n",
      "Pred1:  1030 , Label1:  1039\n",
      "Pred0:  498 , Label0:  500\n",
      "Pred1:  820 , Label1:  830\n",
      "Pred0:  555 , Label0:  600\n",
      "Pred1:  2177 , Label1:  2139\n",
      "Pred0:  432 , Label0:  473\n",
      "Pred1:  774 , Label1:  772\n",
      "Pred0:  434 , Label0:  499\n",
      "Pred1:  1118 , Label1:  1119\n",
      "Pred0:  882 , Label0:  900\n",
      "Pred1:  1591 , Label1:  1558\n",
      "Pred0:  402 , Label0:  400\n",
      "Pred1:  686 , Label1:  684\n",
      "Pred0:  460 , Label0:  500\n",
      "Pred1:  1877 , Label1:  1878\n",
      "Pred0:  785 , Label0:  800\n",
      "Pred1:  1731 , Label1:  1811\n",
      "Pred0:  658 , Label0:  700\n",
      "Pred1:  1082 , Label1:  1083\n",
      "Pred0:  870 , Label0:  900\n",
      "Pred1:  1647 , Label1:  1659\n",
      "Pred0:  392 , Label0:  400\n",
      "Pred1:  656 , Label1:  661\n",
      "Pred0:  819 , Label0:  800\n",
      "Pred1:  1758 , Label1:  1750\n",
      "Pred0:  901 , Label0:  901\n",
      "Pred1:  1558 , Label1:  1553\n",
      "Pred0:  792 , Label0:  801\n",
      "Pred1:  1060 , Label1:  1056\n",
      "Pred0:  670 , Label0:  700\n",
      "Pred1:  1312 , Label1:  1323\n",
      "Pred0:  535 , Label0:  599\n",
      "Pred1:  854 , Label1:  857\n",
      "Pred0:  498 , Label0:  500\n",
      "Pred1:  680 , Label1:  680\n",
      "Pred0:  782 , Label0:  800\n",
      "Pred1:  1171 , Label1:  1170\n",
      "Pred0:  492 , Label0:  500\n",
      "Pred1:  1061 , Label1:  1068\n",
      "Pred0:  827 , Label0:  800\n",
      "Pred1:  1178 , Label1:  1180\n",
      "Pred0:  902 , Label0:  899\n",
      "Pred1:  1226 , Label1:  1227\n",
      "Pred0:  696 , Label0:  700\n",
      "Pred1:  1339 , Label1:  1354\n",
      "Pred0:  589 , Label0:  600\n",
      "Pred1:  1204 , Label1:  1212\n",
      "Pred0:  600 , Label0:  600\n",
      "Pred1:  876 , Label1:  879\n",
      "Pred0:  587 , Label0:  600\n",
      "Pred1:  1595 , Label1:  1582\n",
      "Pred0:  401 , Label0:  400\n",
      "Pred1:  660 , Label1:  654\n",
      "Pred0:  881 , Label0:  900\n",
      "Pred1:  1195 , Label1:  1203\n",
      "Pred0:  856 , Label0:  899\n",
      "Pred1:  1618 , Label1:  1614\n",
      "Pred0:  891 , Label0:  896\n",
      "Pred1:  1875 , Label1:  1940\n",
      "Pred0:  396 , Label0:  400\n",
      "Pred1:  634 , Label1:  644\n",
      "Pred0:  682 , Label0:  700\n",
      "Pred1:  1571 , Label1:  1573\n",
      "Pred0:  610 , Label0:  600\n",
      "Pred1:  1054 , Label1:  1068\n",
      "Pred0:  403 , Label0:  400\n",
      "Pred1:  718 , Label1:  742\n",
      "Pred0:  872 , Label0:  900\n",
      "Pred1:  1247 , Label1:  1268\n",
      "Pred0:  699 , Label0:  700\n",
      "Pred1:  1538 , Label1:  1544\n",
      "Pred0:  411 , Label0:  400\n",
      "Pred1:  1370 , Label1:  1350\n",
      "Pred0:  804 , Label0:  800\n",
      "Pred1:  2519 , Label1:  2510\n",
      "Pred0:  878 , Label0:  900\n",
      "Pred1:  1444 , Label1:  1450\n",
      "Pred0:  948 , Label0:  900\n",
      "Pred1:  2012 , Label1:  2040\n",
      "Pred0:  698 , Label0:  700\n",
      "Pred1:  996 , Label1:  1000\n",
      "Pred0:  478 , Label0:  500\n",
      "Pred1:  692 , Label1:  693\n",
      "Pred0:  901 , Label0:  900\n",
      "Pred1:  1731 , Label1:  1738\n",
      "Pred0:  944 , Label0:  1000\n",
      "Pred1:  1779 , Label1:  1716\n",
      "Pred0:  514 , Label0:  500\n",
      "Pred1:  998 , Label1:  998\n",
      "Pred0:  602 , Label0:  597\n",
      "Pred1:  894 , Label1:  898\n",
      "Pred0:  585 , Label0:  600\n",
      "Pred1:  953 , Label1:  954\n",
      "Pred0:  493 , Label0:  500\n",
      "Pred1:  591 , Label1:  601\n",
      "Pred0:  557 , Label0:  500\n",
      "Pred1:  4999 , Label1:  1612\n",
      "Pred0:  559 , Label0:  600\n",
      "Pred1:  890 , Label1:  894\n",
      "Pred0:  891 , Label0:  900\n",
      "Pred1:  1815 , Label1:  1817\n",
      "Pred0:  786 , Label0:  799\n",
      "Pred1:  1331 , Label1:  1327\n",
      "Pred0:  907 , Label0:  900\n",
      "Pred1:  1700 , Label1:  1694\n",
      "Pred0:  907 , Label0:  900\n",
      "Pred1:  1343 , Label1:  1340\n",
      "Pred0:  794 , Label0:  800\n",
      "Pred1:  1016 , Label1:  1009\n",
      "Pred0:  833 , Label0:  700\n",
      "Pred1:  2456 , Label1:  2475\n",
      "Pred0:  661 , Label0:  700\n",
      "Pred1:  1451 , Label1:  1452\n",
      "Pred0:  790 , Label0:  800\n",
      "Pred1:  2135 , Label1:  2144\n",
      "Pred0:  794 , Label0:  800\n",
      "Pred1:  1094 , Label1:  1057\n",
      "Pred0:  494 , Label0:  500\n",
      "Pred1:  787 , Label1:  791\n",
      "Pred0:  882 , Label0:  900\n",
      "Pred1:  1971 , Label1:  1959\n",
      "Pred0:  499 , Label0:  500\n",
      "Pred1:  720 , Label1:  738\n",
      "Pred0:  494 , Label0:  500\n",
      "Pred1:  686 , Label1:  696\n",
      "Pred0:  57 , Label0:  384\n",
      "Pred1:  507 , Label1:  511\n",
      "Pred0:  706 , Label0:  702\n",
      "Pred1:  1323 , Label1:  1322\n",
      "Pred0:  760 , Label0:  787\n",
      "Pred1:  1563 , Label1:  1599\n",
      "Pred0:  1203 , Label0:  500\n",
      "Pred1:  2227 , Label1:  2239\n",
      "Pred0:  782 , Label0:  799\n",
      "Pred1:  961 , Label1:  964\n",
      "Pred0:  401 , Label0:  400\n",
      "Pred1:  1199 , Label1:  1153\n",
      "Pred0:  788 , Label0:  800\n",
      "Pred1:  1109 , Label1:  1115\n",
      "Pred0:  767 , Label0:  800\n",
      "Pred1:  1183 , Label1:  1195\n",
      "Pred0:  598 , Label0:  600\n",
      "Pred1:  1078 , Label1:  1059\n",
      "Pred0:  594 , Label0:  600\n",
      "Pred1:  730 , Label1:  737\n",
      "Pred0:  722 , Label0:  700\n",
      "Pred1:  1167 , Label1:  1157\n",
      "Pred0:  491 , Label0:  500\n",
      "Pred1:  2055 , Label1:  2028\n",
      "Pred0:  647 , Label0:  700\n",
      "Pred1:  1039 , Label1:  1051\n",
      "Pred0:  584 , Label0:  900\n",
      "Pred1:  1293 , Label1:  1296\n",
      "Pred0:  600 , Label0:  600\n",
      "Pred1:  886 , Label1:  881\n",
      "Pred0:  569 , Label0:  500\n",
      "Pred1:  1607 , Label1:  1633\n",
      "Pred0:  607 , Label0:  600\n",
      "Pred1:  851 , Label1:  850\n",
      "Pred0:  794 , Label0:  797\n",
      "Pred1:  1324 , Label1:  1325\n",
      "Pred0:  771 , Label0:  799\n",
      "Pred1:  1168 , Label1:  1160\n",
      "Pred0:  794 , Label0:  800\n",
      "Pred1:  1011 , Label1:  1018\n",
      "Pred0:  1019 , Label0:  400\n",
      "Pred1:  1875 , Label1:  1885\n",
      "Pred0:  579 , Label0:  600\n",
      "Pred1:  1379 , Label1:  1383\n",
      "Pred0:  494 , Label0:  500\n",
      "Pred1:  772 , Label1:  768\n",
      "Pred0:  822 , Label0:  799\n",
      "Pred1:  1223 , Label1:  1219\n",
      "Pred0:  586 , Label0:  600\n",
      "Pred1:  785 , Label1:  786\n",
      "Pred0:  700 , Label0:  700\n",
      "Pred1:  931 , Label1:  990\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  719 , Label1:  721\n",
      "Pred0:  502 , Label0:  500\n",
      "Pred1:  1512 , Label1:  1526\n",
      "Pred0:  398 , Label0:  400\n",
      "Pred1:  1251 , Label1:  1217\n",
      "Pred0:  478 , Label0:  500\n",
      "Pred1:  504 , Label1:  677\n",
      "Pred0:  589 , Label0:  600\n",
      "Pred1:  1567 , Label1:  1586\n",
      "Pred0:  474 , Label0:  500\n",
      "Pred1:  1379 , Label1:  1369\n",
      "Pred0:  395 , Label0:  400\n",
      "Pred1:  1411 , Label1:  1407\n",
      "Pred0:  586 , Label0:  600\n",
      "Pred1:  1378 , Label1:  1402\n",
      "Pred0:  394 , Label0:  400\n",
      "Pred1:  815 , Label1:  813\n",
      "Pred0:  476 , Label0:  500\n",
      "Pred1:  1067 , Label1:  1070\n",
      "Pred0:  437 , Label0:  500\n",
      "Pred1:  1061 , Label1:  1065\n",
      "Pred0:  578 , Label0:  600\n",
      "Pred1:  821 , Label1:  898\n",
      "Pred0:  696 , Label0:  700\n",
      "Pred1:  959 , Label1:  968\n",
      "Pred0:  850 , Label0:  900\n",
      "Pred1:  1624 , Label1:  1605\n",
      "Pred0:  706 , Label0:  702\n",
      "Pred1:  1127 , Label1:  1117\n",
      "Pred0:  666 , Label0:  700\n",
      "Pred1:  1236 , Label1:  1239\n",
      "Pred0:  880 , Label0:  900\n",
      "Pred1:  1700 , Label1:  1705\n",
      "Pred0:  891 , Label0:  900\n",
      "Pred1:  2282 , Label1:  2313\n",
      "Pred0:  810 , Label0:  800\n",
      "Pred1:  2183 , Label1:  2186\n",
      "Pred0:  688 , Label0:  700\n",
      "Pred1:  1132 , Label1:  1132\n",
      "Pred0:  898 , Label0:  895\n",
      "Pred1:  1290 , Label1:  1293\n",
      "Pred0:  699 , Label0:  700\n",
      "Pred1:  884 , Label1:  888\n",
      "Pred0:  598 , Label0:  600\n",
      "Pred1:  1412 , Label1:  1422\n",
      "Pred0:  395 , Label0:  399\n",
      "Pred1:  623 , Label1:  624\n",
      "Pred0:  592 , Label0:  610\n",
      "Pred1:  990 , Label1:  990\n",
      "Pred0:  477 , Label0:  500\n",
      "Pred1:  1446 , Label1:  1447\n",
      "Pred0:  886 , Label0:  900\n",
      "Pred1:  1830 , Label1:  1840\n",
      "Pred0:  769 , Label0:  700\n",
      "Pred1:  2647 , Label1:  2547\n",
      "Pred0:  592 , Label0:  600\n",
      "Pred1:  818 , Label1:  814\n",
      "Pred0:  598 , Label0:  600\n",
      "Pred1:  1715 , Label1:  1703\n",
      "Pred0:  487 , Label0:  500\n",
      "Pred1:  1407 , Label1:  1415\n",
      "Pred0:  694 , Label0:  701\n",
      "Pred1:  860 , Label1:  868\n",
      "Pred0:  397 , Label0:  400\n",
      "Pred1:  1553 , Label1:  1555\n",
      "Pred0:  452 , Label0:  500\n",
      "Pred1:  840 , Label1:  844\n",
      "Pred0:  705 , Label0:  700\n",
      "Pred1:  1543 , Label1:  1562\n",
      "Pred0:  593 , Label0:  600\n",
      "Pred1:  1831 , Label1:  2038\n",
      "Pred0:  792 , Label0:  801\n",
      "Pred1:  1026 , Label1:  1020\n",
      "Pred0:  882 , Label0:  900\n",
      "Pred1:  1675 , Label1:  1692\n",
      "Pred0:  506 , Label0:  500\n",
      "Pred1:  1054 , Label1:  1074\n",
      "Pred0:  751 , Label0:  800\n",
      "Pred1:  1895 , Label1:  1884\n",
      "Pred0:  786 , Label0:  800\n",
      "Pred1:  1556 , Label1:  1555\n",
      "Pred0:  514 , Label0:  500\n",
      "Pred1:  910 , Label1:  897\n",
      "Pred0:  392 , Label0:  400\n",
      "Pred1:  1123 , Label1:  1095\n",
      "Pred0:  409 , Label0:  400\n",
      "Pred1:  381 , Label1:  505\n",
      "Pred0:  912 , Label0:  900\n",
      "Pred1:  1999 , Label1:  1979\n",
      "Pred0:  472 , Label0:  500\n",
      "Pred1:  840 , Label1:  840\n",
      "Pred0:  394 , Label0:  400\n",
      "Pred1:  1228 , Label1:  1221\n",
      "Pred0:  5682 , Label0:  600\n",
      "Pred1:  2131 , Label1:  2132\n",
      "Pred0:  878 , Label0:  900\n",
      "Pred1:  1788 , Label1:  1828\n",
      "Pred0:  455 , Label0:  495\n",
      "Pred1:  971 , Label1:  973\n",
      "Pred0:  575 , Label0:  600\n",
      "Pred1:  911 , Label1:  919\n",
      "Pred0:  692 , Label0:  701\n",
      "Pred1:  978 , Label1:  980\n",
      "Pred0:  2352 , Label0:  500\n",
      "Pred1:  1983 , Label1:  1910\n",
      "Pred0:  390 , Label0:  399\n",
      "Pred1:  526 , Label1:  547\n",
      "Pred0:  422 , Label0:  400\n",
      "Pred1:  731 , Label1:  740\n",
      "Pred0:  474 , Label0:  500\n",
      "Pred1:  1140 , Label1:  1124\n",
      "Pred0:  791 , Label0:  800\n",
      "Pred1:  1113 , Label1:  1070\n",
      "Pred0:  890 , Label0:  898\n",
      "Pred1:  1342 , Label1:  1336\n",
      "Pred0:  398 , Label0:  400\n",
      "Pred1:  1027 , Label1:  1038\n",
      "Pred0:  394 , Label0:  400\n",
      "Pred1:  1247 , Label1:  1244\n",
      "Pred0:  671 , Label0:  600\n",
      "Pred1:  1783 , Label1:  1764\n",
      "Pred0:  400 , Label0:  400\n",
      "Pred1:  622 , Label1:  620\n",
      "Pred0:  670 , Label0:  662\n",
      "Pred1:  1695 , Label1:  1695\n",
      "Pred0:  474 , Label0:  500\n",
      "Pred1:  787 , Label1:  782\n",
      "Pred0:  890 , Label0:  900\n",
      "Pred1:  1110 , Label1:  1114\n",
      "Pred0:  696 , Label0:  701\n",
      "Pred1:  1211 , Label1:  1221\n",
      "Pred0:  401 , Label0:  400\n",
      "Pred1:  1238 , Label1:  1217\n",
      "Pred0:  694 , Label0:  701\n",
      "Pred1:  946 , Label1:  959\n",
      "Pred0:  762 , Label0:  800\n",
      "Pred1:  1130 , Label1:  1115\n",
      "Pred0:  792 , Label0:  800\n",
      "Pred1:  1007 , Label1:  1006\n",
      "Pred0:  883 , Label0:  908\n",
      "Pred1:  1310 , Label1:  1311\n",
      "Pred0:  897 , Label0:  900\n",
      "Pred1:  1134 , Label1:  1133\n",
      "Pred0:  404 , Label0:  400\n",
      "Pred1:  790 , Label1:  794\n",
      "Pred0:  577 , Label0:  600\n",
      "Pred1:  1308 , Label1:  1339\n",
      "Pred0:  1111 , Label0:  900\n",
      "Pred1:  2647 , Label1:  2810\n",
      "Pred0:  486 , Label0:  500\n",
      "Pred1:  775 , Label1:  771\n",
      "Pred0:  388 , Label0:  400\n",
      "Pred1:  638 , Label1:  649\n",
      "Pred0:  472 , Label0:  500\n",
      "Pred1:  991 , Label1:  1009\n",
      "Pred0:  795 , Label0:  800\n",
      "Pred1:  1320 , Label1:  1318\n",
      "Pred0:  594 , Label0:  600\n",
      "Pred1:  852 , Label1:  851\n",
      "Pred0:  671 , Label0:  700\n",
      "Pred1:  1483 , Label1:  1498\n",
      "Pred0:  408 , Label0:  400\n",
      "Pred1:  556 , Label1:  561\n",
      "Pred0:  1422 , Label0:  500\n",
      "Pred1:  2667 , Label1:  2689\n",
      "Pred0:  786 , Label0:  800\n",
      "Pred1:  1014 , Label1:  1029\n",
      "Pred0:  886 , Label0:  900\n",
      "Pred1:  1438 , Label1:  1444\n",
      "Pred0:  562 , Label0:  600\n",
      "Pred1:  1476 , Label1:  1461\n",
      "Pred0:  393 , Label0:  400\n",
      "Pred1:  565 , Label1:  576\n",
      "Pred0:  479 , Label0:  500\n",
      "Pred1:  595 , Label1:  605\n",
      "Pred0:  677 , Label0:  700\n",
      "Pred1:  1703 , Label1:  1698\n",
      "Pred0:  454 , Label0:  500\n",
      "Pred1:  771 , Label1:  823\n",
      "Pred0:  506 , Label0:  500\n",
      "Pred1:  1028 , Label1:  1031\n",
      "Pred0:  578 , Label0:  597\n",
      "Pred1:  899 , Label1:  903\n",
      "Pred0:  390 , Label0:  400\n",
      "Pred1:  610 , Label1:  601\n",
      "Pred0:  682 , Label0:  700\n",
      "Pred1:  1536 , Label1:  1528\n",
      "Pred0:  590 , Label0:  600\n",
      "Pred1:  902 , Label1:  897\n",
      "Pred0:  620 , Label0:  600\n",
      "Pred1:  954 , Label1:  953\n",
      "Pred0:  406 , Label0:  400\n",
      "Pred1:  1663 , Label1:  1624\n",
      "Pred0:  602 , Label0:  600\n",
      "Pred1:  1290 , Label1:  1272\n",
      "Pred0:  898 , Label0:  900\n",
      "Pred1:  1096 , Label1:  1097\n",
      "Pred0:  878 , Label0:  899\n",
      "Pred1:  1413 , Label1:  1416\n",
      "Pred0:  1017 , Label0:  400\n",
      "Pred1:  1843 , Label1:  1829\n",
      "Pred0:  394 , Label0:  400\n",
      "Pred1:  722 , Label1:  715\n",
      "Pred0:  862 , Label0:  900\n",
      "Pred1:  1237 , Label1:  1250\n",
      "Pred0:  598 , Label0:  600\n",
      "Pred1:  878 , Label1:  887\n",
      "Pred0:  804 , Label0:  800\n",
      "Pred1:  1328 , Label1:  1311\n",
      "Pred0:  598 , Label0:  600\n",
      "Pred1:  783 , Label1:  811\n",
      "Pred0:  1237 , Label0:  700\n",
      "Pred1:  1787 , Label1:  1792\n",
      "Pred0:  807 , Label0:  800\n",
      "Pred1:  1859 , Label1:  1846\n",
      "Pred0:  627 , Label0:  600\n",
      "Pred1:  1019 , Label1:  1020\n",
      "Pred0:  786 , Label0:  801\n",
      "Pred1:  1242 , Label1:  1253\n",
      "Pred0:  663 , Label0:  700\n",
      "Pred1:  1083 , Label1:  1106\n",
      "Pred0:  900 , Label0:  900\n",
      "Pred1:  1314 , Label1:  1316\n",
      "Pred0:  594 , Label0:  599\n",
      "Pred1:  830 , Label1:  833\n",
      "Pred0:  784 , Label0:  800\n",
      "Pred1:  1854 , Label1:  1868\n",
      "Pred0:  638 , Label0:  600\n",
      "Pred1:  1270 , Label1:  1281\n",
      "Pred0:  490 , Label0:  500\n",
      "Pred1:  730 , Label1:  740\n",
      "Pred0:  468 , Label0:  498\n",
      "Pred1:  840 , Label1:  841\n",
      "Pred0:  437 , Label0:  400\n",
      "Pred1:  1559 , Label1:  1552\n",
      "Pred0:  502 , Label0:  500\n",
      "Pred1:  1044 , Label1:  1052\n",
      "Pred0:  463 , Label0:  500\n",
      "Pred1:  1651 , Label1:  1656\n",
      "Pred0:  907 , Label0:  900\n",
      "Pred1:  1951 , Label1:  1950\n",
      "Pred0:  877 , Label0:  900\n",
      "Pred1:  1643 , Label1:  1640\n",
      "Pred0:  901 , Label0:  900\n",
      "Pred1:  1135 , Label1:  1142\n",
      "Pred0:  617 , Label0:  600\n",
      "Pred1:  1268 , Label1:  1272\n",
      "Pred0:  580 , Label0:  600\n",
      "Pred1:  963 , Label1:  950\n",
      "Pred0:  412 , Label0:  400\n",
      "Pred1:  639 , Label1:  643\n",
      "Pred0:  730 , Label0:  800\n",
      "Pred1:  955 , Label1:  974\n",
      "Pred0:  782 , Label0:  800\n",
      "Pred1:  1155 , Label1:  1160\n",
      "Pred0:  878 , Label0:  900\n",
      "Pred1:  1700 , Label1:  1699\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_waves):\n",
    "    print(\"Pred0: \", int(pick_preds_pn[i][0]), \", Label0: \", int(labels[i][0]))\n",
    "    print(\"Pred1: \", int(pick_preds_pn[i][1]), \", Label1: \", int(labels[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total events in csv file: 200000\n",
      "total events selected: 200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jp/cc_r_y3x6clgl7b4rwk3lgfw0000gn/T/ipykernel_66615/730885282.py:7: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back_azimuth_deg 92.5\n",
      "coda_end_sample [[1271.]]\n",
      "network_code PB\n",
      "p_arrival_sample 599.0\n",
      "p_status autopicker\n",
      "p_travel_sec 2.7799999713897705\n",
      "p_weight 0.94\n",
      "receiver_code B087\n",
      "receiver_elevation_m 1139.0\n",
      "receiver_latitude 33.4955\n",
      "receiver_longitude -116.602667\n",
      "receiver_type EH\n",
      "s_arrival_sample 801.0\n",
      "s_status autopicker\n",
      "s_weight 0.84\n",
      "snr_db [39.29999924 35.90000153 35.5       ]\n",
      "source_depth_km 10.3\n",
      "source_depth_uncertainty_km 0.68\n",
      "source_distance_deg 0.09954\n",
      "source_distance_km 11.07\n",
      "source_error_sec 0.22\n",
      "source_gap_deg 97.0\n",
      "source_horizontal_uncertainty_km 0.36\n",
      "source_id ci15072004\n",
      "source_latitude 33.4911667\n",
      "source_longitude -116.4836667\n",
      "source_magnitude 1.22\n",
      "source_magnitude_author CI\n",
      "source_magnitude_type ml\n",
      "source_mechanism_strike_dip_rake None\n",
      "source_origin_time 2011-11-03 06:28:09.000000\n",
      "source_origin_uncertainty_sec nan\n",
      "trace_category earthquake_local\n",
      "trace_name B087.PB_20111103062804_EV\n",
      "trace_start_time 2011-11-03 06:28:05.790000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m at \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(at, dataset\u001b[38;5;241m.\u001b[39mattrs[at])    \n\u001b[0;32m---> 67\u001b[0m inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPress a key to plot the next waveform!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inp \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reading the csv file into a dataframe:\n",
    "df = pd.read_csv(csv_file)\n",
    "print(f'total events in csv file: {len(df)}')\n",
    "# filterering the dataframe\n",
    "#df = df[(df.trace_category == 'earthquake_local') & (df.source_distance_km <= 20) & (df.source_magnitude > 3)]\n",
    "print(f'total events selected: {len(df)}')\n",
    "\n",
    "# making a list of trace names for the selected data\n",
    "ev_list = df['trace_name'].to_list()\n",
    "\n",
    "# retrieving selected waveforms from the hdf5 file: \n",
    "dtfl = h5py.File(file_name, 'r')\n",
    "for c, evi in enumerate(ev_list):\n",
    "    dataset = dtfl.get('data/'+str(evi)) \n",
    "    # waveforms, 3 channels: first row: E channel, second row: N channel, third row: Z channel \n",
    "    data = np.array(dataset)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(311)         \n",
    "    plt.plot(data[:,0], 'k')\n",
    "    plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "    legend_properties = {'weight':'bold'}    \n",
    "    plt.tight_layout()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    pl = plt.vlines(dataset.attrs['p_arrival_sample'], ymin, ymax, color='b', linewidth=2, label='P-arrival')\n",
    "    sl = plt.vlines(dataset.attrs['s_arrival_sample'], ymin, ymax, color='r', linewidth=2, label='S-arrival')\n",
    "    cl = plt.vlines(dataset.attrs['coda_end_sample'], ymin, ymax, color='aqua', linewidth=2, label='Coda End')\n",
    "    plt.legend(handles=[pl, sl, cl], loc = 'upper right', borderaxespad=0., prop=legend_properties)        \n",
    "    plt.ylabel('Amplitude counts', fontsize=12) \n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "    ax = fig.add_subplot(312)         \n",
    "    plt.plot(data[:,1], 'k')\n",
    "    plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "    legend_properties = {'weight':'bold'}    \n",
    "    plt.tight_layout()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    pl = plt.vlines(dataset.attrs['p_arrival_sample'], ymin, ymax, color='b', linewidth=2, label='P-arrival')\n",
    "    sl = plt.vlines(dataset.attrs['s_arrival_sample'], ymin, ymax, color='r', linewidth=2, label='S-arrival')\n",
    "    cl = plt.vlines(dataset.attrs['coda_end_sample'], ymin, ymax, color='aqua', linewidth=2, label='Coda End')\n",
    "    plt.legend(handles=[pl, sl, cl], loc = 'upper right', borderaxespad=0., prop=legend_properties)        \n",
    "    plt.ylabel('Amplitude counts', fontsize=12) \n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "    ax = fig.add_subplot(313)         \n",
    "    plt.plot(data[:,2], 'k')\n",
    "    plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "    legend_properties = {'weight':'bold'}    \n",
    "    plt.tight_layout()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    pl = plt.vlines(dataset.attrs['p_arrival_sample'], ymin, ymax, color='b', linewidth=2, label='P-arrival')\n",
    "    sl = plt.vlines(dataset.attrs['s_arrival_sample'], ymin, ymax, color='r', linewidth=2, label='S-arrival')\n",
    "    cl = plt.vlines(dataset.attrs['coda_end_sample'], ymin, ymax, color='aqua', linewidth=2, label='Coda End')\n",
    "    plt.legend(handles=[pl, sl, cl], loc = 'upper right', borderaxespad=0., prop=legend_properties)        \n",
    "    plt.ylabel('Amplitude counts', fontsize=12) \n",
    "    ax.set_xticklabels([])\n",
    "    plt.show() \n",
    "\n",
    "    for at in dataset.attrs:\n",
    "        print(at, dataset.attrs[at])    \n",
    "\n",
    "    inp = input(\"Press a key to plot the next waveform!\")\n",
    "    if inp == \"r\":\n",
    "        continue             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
